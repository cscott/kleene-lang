
\documentclass[letterpaper,11pt]{article}
% \documentclass[a4paper,12pt]{article}
% twocolumn letterpaper 10pt 11pt twoside

% for other type sizes, 8, 9, 10, 11, 12, 14pt, 17pt, 20pt
% \documentclass[14pt]{extarticle}
% also extbook, extletter available
% \usepackage{extsizes}

%\usepackage{endnotes}
% then put \theendnotes where you want them

\usepackage{times}
\usepackage{xspace}
\usepackage{alltt}
\usepackage{fancyvrb}  % \begin{Verbatim}[fontsize=\small]
% or [fontsize=\footnotesize]

%\usepackage{latexsym}  % \LaTeX{} for LaTeX;  \LaTeXe{} for LaTeX2e
%\usepackage{mflogo}    % \MF{}  for METAFONT;  \MP for METAPOST
\usepackage{url}       % \url{http://www.xrce.xerox.com/people/beesley}
\usepackage{lscape}

%\usepackage{tipa}
%\include{ipamacros}  % my macros to allow same input for DA and IPA
%\usepackage{desalph}
%\usepackage{arabtex} % see usepackage{buck} and setcode{buck} below
%\usepackage{buck}
%\usepackage{mxedruli}

%\usepackage{epsfig}
%\usepackage{pslatex}  % make whole doc. use postscript fonts

%\usepackage{upquote}
% affects \verb and verbatim
% to get straight quotes, straight single quote, straight double
% quotes in verbatim environments

% parallel columns, see also multicol
%\usepackage{parcolumns}
%...
%\begin{parcolumns}[<options>]{3}
%\colchunk{ column 1 text }
%\colchunk{ column 2 text }
%\colchunk{ column 3 text }
%\colplacechunks
%...
%\end{parcolumns}


% for more of these names, see Guide to LaTeX, p. 351
%\providecommand*{\abstractname}{}     % in case the style defines one
%\renewcommand*{\abstractname}{Transcriber notes}
%\renewcommand*{\figurename}{Figure}
%\renewcommand*{\tablename}{Table}
%\renewcommand*{\bibname}{Bibliography}
%\renewcommand*{\refname}{References}

\providecommand{\acro}{}\renewcommand{\acro}{\textsc}
\providecommand{\defin}{}\renewcommand{\defin}{\textsc}

\newcommand{\xmlelmt}{\texttt}
\newcommand{\xmlattr}{\texttt}
\newcommand{\key}{\textbf}
\newcommand{\translit}{\texttt}

% forced pagebreak
%\newpage

%\usepackage{ulem}
%    \uline{important}   underlined text
%    \uuline{urgent}     double-underlined text
%    \uwave{boat}        wavy underline
%    \sout{wrong}        line drawn through word (cross out, strike out)
%    \xout{removed}      marked over with //////.
%    {\em phasized\/}  | In LaTeX, by default, these are underlined; use
%    \emph{asized}     | \normalem or [normalem] to restore italics
%    \useunder{\uwave}{\bfseries}{\textbf}
%                        use wavy underline in place of bold face


%                        \usepackage{natbib}
%\usepackage[authoryear]{natbib}
% compatible with \bibliographystyle{plain}, harvard, apalike, chicago, astron, authordate

%\citet for "textual"   \citet{jon90} ->  Jones et al. (1990)
%\citet[before][after]{key} e.g. \citet[see][p.~47]{jon90} --> 
%         see Jones et al.(1990, chap. 2)
%\citet[chap. 2]{jon90}	    -->    	Jones et al. (1990, chap. 2)
%\citet[after]{key}

%   citep for "parenthetical"
%\citep{jon90}	    -->    	(Jones et al., 1990)
%\citep[chap. 2]{jon90}	    -->    	(Jones et al., 1990, chap. 2)
%\citep[see][]{jon90}	    -->    	(see Jones et al., 1990)
%\citep[see][chap. 2]{jon90}	    -->    	(see Jones et al., 1990, chap. 2)

%\citep for "parenthetical" (author's name in parens)
%\citep  similar
%
%\citet*{key}  list all authors, not just et.al
%\citetext{priv.\ comm.} comes out as (priv. comm.)
%
%just the author or year
%\citeauthor{key} comes out as "Jones et al."
%\citeauthor*{key} comes out as "Jones, Sacco and Vanzetti"
%\citeyear{key}   comes out as 1990
%\citeyearpar{key}            (1990)
%
%Rare stuff:
%use \Citet and \Citep for exceptional forcing of initcap on names
%like 'della Robbia' when it appears first in a sentence.
%
%\citealt like \citet but without parens
%\citealp like \citep but without parens
%


% fancyheadings from The Book (old, obsolete, I think)
%\usepackage{fancyheadings}
%\pagestyle{fancyplain}
% remember the chapter title
%\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
%\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
%\lhead[\fancyplain{}{\small\scshape\thepage}]{\fancyplain{}{\small\scshape\rightmark}}
%\rhead[\fancyplain{}{\small\scshape\leftmark}]{\fancyplain{}{\small\scshape\thepage}}
%\cfoot{}

% new fancyhdr package
%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\fancyhead{}

%% L/C/R denote left/center/right header (or footer) elements
%% E/O denote even/odd pages

%% \leftmark, \rightmark are chapter/section headings generated by the 
%% book document class

%\fancyhead[LE,RO]{\slshape\thepage}
%\fancyhead[RE]{\slshape \leftmark}
%\fancyhead[LO]{\slshape \rightmark}
%\fancyfoot[LO,LE]{\slshape Short Course on Asymptotics}
%\fancyfoot[C]{}
%\fancyfoot[RO,RE]{\slshape 7/15/2002}

% another example
%\fancyhead[LE]{\thepage}
%\fancyhead[CE]{\bfseries Beesley}
%\fancyfoot[CE]{First Draft}
%\fancyhead[CO]{\bfseries My Article Title}
%\fancyhead[RO]{\thepage}
%\fancyfoot[CO]{For Review and Editing Only}
%\renewcommand{\footrulewidth}{0.4pt}

% \vspace{.5cm}
% c, l, r, p{1cm}
%\begin{tabular}{}
%\hline
%   &  &  &   \\
%\hline
%\end{tabular}
% \vspace{.5cm}


% bigbox -- puts a box around a float
% for {figure}, {table} or {center}

\newdimen\boxfigwidth  % width of figure box

\def\bigbox{\begingroup
  % Figure out how wide to set the box in
  \boxfigwidth=\hsize
  \advance\boxfigwidth by -2\fboxrule
  \advance\boxfigwidth by -2\fboxsep
  \setbox4=\vbox\bgroup\hsize\boxfigwidth
  % Make an invisible hrule so that
  % the box is exactly this wide
  \hrule height0pt width\boxfigwidth\smallskip%
% Some environments like TABBING and other LIST environments
% use this measure of line size -
% \LINEWIDTH=\HSIZE-\LEFTMARGIN-\RIGHTMARGIN?
  \linewidth=\boxfigwidth
}
\def\endbigbox{\smallskip\egroup\fbox{\box4}\endgroup}


% example
% \begin{figure}
%   \begin{bigbox}
%     \begin{whatever}...\end{whatever}
%     \caption{}
%     \label{}
%   \end{bigbox}
% \end{figure}
% 
% N.B. put the caption and label inside the bigbox

%\usepackage{graphicx}
% Sample Graphics inclusion; needs graphicx package
%\begin{figure}[ht]
%\begin{bigbox}
%\centering
%\includegraphics{foobar.pdf}   # e.g. PNG, PDF or JPG, _not_ EPS
%\caption{}
%\label{lab:XXX}
%\end{bigbox}
%\end{figure}

%\pagestyle{empty}  % to suppress page numbering

% turn text upside down
%\reflectbox{\textipa{\textlhookp}}
% prevent line break:   \mbox{...}

\hyphenation{hy-po-cri-tical ri-bald}

%%%%%%%%%%%%%%%%%%%%  title %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Adding the Concept of the \acro{other} Symbol\\
into Kleene/OpenFst Finite-State Networks:\\
The Xerox/\acro{parc} Model}
\author{Kenneth R.~Beesley}

% to override automatic "today" date
\date{Last edits: 10 December 2009}

%\usepackage{makeidx}
%\makeindex
% see \printindex below in the document
%\usepackage{showidx}   % print proofs showing indexed locations!!!

%%%%%%%%%%%%%%%%%%%%%% document %%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\begin{abstract}
Most implementations of regular theory/automata 
including \acro{sfst} and OpenFst require a
global, pre-defined and closed alphabet or \emph{sigma} ($\Sigma$, a finite set
of known symbols) in order to support the notion of 
\acro{any} symbol and
to compute complementations (also known as negations).  In these implementations,
the notion of the
\acro{any} symbol logically matches
any single symbol that is a member of the pre-defined sigma; [\^{}abc] matches any single symbol
from the sigma, except \emph{a}, \emph{b} and \emph{c}, i.e.\@
\texttt{Sigma -
(a|b|c)}; and where \verb!L! encodes a regular language, \verb!~L!
(the complement or negation of L) is \texttt{Sigma* - L}.  

The Xerox/\acro{parc} implementation of finite-state networks is, in my opinion,
more sophisticated in this regard, not requiring any pre-definition
of the sigma, and
automatically maintaining for each network a private sigma, which contains literal
symbols like \emph{a}, \emph{b} and \emph{c} that are known to the network, and
which may also contain a special \acro{other} (also known as \acro{unknown}) symbol, 
which matches any possible symbol except those that are explicitly
listed (and so are ``known'') in the private sigma.  
The advantage is that users of the Xerox/\acro{parc} implementation
never have to define the sigma manually; the challenge is that when the Xerox/\acro{parc} library
algorithms combine any two networks, the sigmas and structures of the two networks must be
``promoted'' non-trivially to create the result network.

This white paper explores the advantages and challenges of \acro{other} and suggests ways that it might be
incorporated into Kleene networks and eventually into Kleene runtime code.
In the last couple of months, we have been exploring a number of possible
solutions, including label ``predicates'', 
but this paper concentrates on an emulation of the
handling of \acro{other} in the Xerox/\acro{parc} implementation.
\end{abstract}

\newpage

\section{Introduction}

\subsection{\acro{other} in the Xerox/\acro{parc} Implementation}

Handling the notion of \acro{other} is genuinely
difficult.  It took Xerox years to get it stable and ``right''.
The Xerox/\acro{parc} way is not the only way---there are several
alternative approaches in
the literature---and it's not, of course, required 
for Kleene/OpenFst that
we handle \acro{other} the same
way.  But the Xerox/\acro{parc}
approach is known to work, and in a commercial environment we
have currently decided to concentrate on this well-tested model.  This paper explores how the
Xerox/\acro{parc} approach could be emulated in Kleene/OpenFst.

\subsection{\acro{any} vs.\@ \acro{other} in Xerox/\acro{parc}}

\subsubsection{Syntax}

In any implementation of finite-state automata, 
it is important to distinguish between the syntax of the
programming formalisms and the semantics of the symbols in the networks built from the
syntax.  In the Xerox/\acro{parc} \texttt{fst} programming language (the
non-commercial version is called
\texttt{xfst}), networks are defined using regular expressions; and in \texttt{fst}
regular expressions, alphabetic symbols like \emph{a}, \emph{b} and \emph{c} represent
themselves, and the question mark \texttt{?} is a special syntactic
token denoting
\acro{any} symbol. This, again, is \emph{syntax} in the
\texttt{(x)fst} programming language.

Let's look first at a very simple Xerox network that contains only one
known symbol, here the letter \emph{a}:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex a ;
340 bytes. 2 states, 1 arc, 1 path. Label Map: Default.
fst[1]: print net
Sigma: a
Size: 1, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   a -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
The network built from the regular expression \texttt{a} will match exactly one
string, i.e.\@ ``a''.  The network is formally understood as encoding a Language, i.e.\@ a
set of strings, which in this case is a set consisting of one member, the string
``a''.  Note especially that the sigma of this network contains only
one symbol, being \emph{a}.

The simplest Xerox regular expression referring to the \acro{any} symbol is of course just
\texttt{?}, as in the following example:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex ? ;
92 bytes. 2 states, 1 arc, 1 path. Label Map: Default.
fst[1]: print net
Sigma: ?
Size: 1, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   ? -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
The special syntactic token \texttt{?} in an \texttt{fst} regular expression
really denotes \emph{any} possible symbol
(including any possible multi-character symbol), and the regular expression \texttt{?}
denotes the infinite language of all single-symbol strings.

Danger:  It is important to distinguish between the
regular-expression syntax used to denote \acro{any}
symbol (in \texttt{(x)fst}, the question mark) and the underlying 
notion of \acro{other}/\acro{unknown}.  \acro{any} is a notion
limited to regular expressions; and \acro{other} is a notion limited
to networks and their sigma.
(For brevity, I will henceforth refer to \acro{other} rather than
\acro{other}/\acro{unknown}.)
\acro{any} is different from \acro{other}.  But in the
Xerox/\acro{parc} \texttt{(x)fst} interface, Lauri Karttunen
insisted on displaying the \acro{other} symbol in the \texttt{print sigma}
and \texttt{print net} output as \texttt{?}, a practice that I (and
everyone else in the world except Lauri) find very confusing.  We argued about this for
years, and I lost.  The example above, where the regular expression
is just \texttt{?}, is
the only example where the syntactic \acro{any} maps
straightforwardly to the underlying semantic
\acro{other}; it is a very special case.  (\acro{any} is genuinely
distinct from \acro{other} in the \acro{parc} implementation; Lauri
just confuses things by displaying the special \acro{other} symbol as the question
mark.)


\subsubsection{Semantics}

In what follows, I will always try to make a
clear distinction between \acro{any} in regular expressions, indicated by whatever syntax, 
which means ``any symbol'' (really \emph{any} possible symbol), vs.\@ the
\acro{other} symbol
in the sigma and labels of a network, which matches any possible symbol minus the
symbols that are explicitly
known in the same sigma.  For a discussion of \acro{any} vs.\@ \acro{other} in the Xerox/\acro{parc}
implementation, see the book \emph{Finite State Morphology}, pp.\@ 56--60, but beware
Karttunen's lamentable usage of \texttt{?} to represent both \acro{any} and \acro{other}.

Let's look at the networks
resulting from the \texttt{fst} regular
expressions \texttt{a~b}
and \texttt{a~?}.  The first denotes the language consisting of one string,
``ab'', and the second denotes the infinite language of all two-symbol strings that start with
\emph{a}.

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex a b ;
368 bytes. 3 states, 2 arcs, 1 path. Label Map: Default.
fst[1]: print net
Sigma: a b
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   a -> s1.
s1:   b -> fs2.
fs2:  (no arcs)
\end{Verbatim}

\begin{Verbatim}[fontsize=\footnotesize]
fst[1]: read regex a ? ;
380 bytes. 3 states, 3 arcs, 2 paths. Label Map: Default.
fst[2]: print net
Sigma: ? a
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   a -> s1.
s1:   ? -> fs2, a -> fs2.
fs2:  (no arcs)
\end{Verbatim}

\noindent
The first example is pretty straightforward.  In the second example,
computed from the regular expression \texttt{a~?}, the sigma is printed
as \texttt{?~a}, meaning \acro{other} and
\emph{a}, where \acro{other} represents (and matches) any possible
symbol 
except for the known symbol \emph{a}.  Note in
the resulting network that there are two arcs from state 1 to state
2, labeled \emph{?} and \emph{a}.  So in this case, the syntactic
notion of \acro{any} has translated non-trivially into two parallel
arcs, one to match \emph{a} and the other to match any symbol
other than \emph{a}.  

The meaning of \acro{other} in Xerox networks always has to be
evaluated in terms of the known symbols in the same sigma, and, as explained above, each network carries its own sigma.

\subsection{Complementation and \acro{other} in Xerox/\acro{parc}}


\subsubsection{Symbol-Set Complementation}

We have already seen that \acro{other} will appear in the sigma when the original regular
expression contains the special \acro{any} symbol, which happens to
be \texttt{?} in \texttt{fst}.
The \acro{other} symbol will also appear automatically when the regular expression
involves complementation.  For example, the Xerox regular expression
\verb!\!\texttt{a} denotes the infinite
language of all single-symbol strings, except for ``a''.  Here's what the resulting
network looks like in the Xerox/\acro{parc} implementation:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex \a ;
340 bytes. 2 states, 1 arc, 1 path. Label Map: Default.
fst[1]: print net
Sigma: ? a
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   ? -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
Note that the sigma contains \acro{other} and \emph{a}, but in the network there is only
a single arc, labeled \acro{other}, and this \acro{other} arc will, in this network, correctly match any
input symbol other than \emph{a}.  In the following example, the
network looks exactly the same,
but the sigma contains \acro{other}, \emph{a}, \emph{b} and
\emph{c}.  So here \acro{other} matches any symbol that is not
\emph{a}, \emph{b} or \emph{c}.

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex \[a|b|c] ;
340 bytes. 2 states, 1 arc, 1 path. Label Map: Default.
fst[1]: print net
Sigma: ? a b c
Size: 4, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   ? -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
Obviously, in the Xerox/\acro{parc} implementation, a physical
network together with its private sigma must be considered an
integrated package.  You cannot interpret, operate on, or apply a network without
knowing its sigma.


\subsubsection{Language Complementation}

If \texttt{L} encodes a regular \emph{language} (not a relation), 
then \texttt{\~{}L} denotes
the complement, mathematically \texttt{Sigma* - L}.  The following example creates a
network that accepts any possible string, of any length (including
the empty string), except for the string ``dog''.  Note that
\acro{other} appears automatically in the sigma, intuitively required to match all
the symbols not explicitly known; and note that the string ``zebra'' is accepted, while
``dog'' is not.

\begin{Verbatim}[fontsize=\footnotesize]

fst[0]: read regex ~[d o g ] ;
616 bytes. 5 states, 20 arcs, Circular. Label Map: Default.
fst[1]: print net
Sigma: ? d g o
Size: 4, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free
Arity: 1
fs0:  ? -> fs1, d -> fs2, g -> fs1, o -> fs1.
fs1:  ? -> fs1, d -> fs1, g -> fs1, o -> fs1.
fs2:  ? -> fs1, d -> fs1, g -> fs1, o -> fs3.
fs3:  ? -> fs1, d -> fs1, g -> s4, o -> fs1.
s4:   ? -> fs1, d -> fs1, g -> fs1, o -> fs1.
fst[1]: apply up zebra
zebra
fst[1]: apply up dog
???
\end{Verbatim}



\subsection{Identity \acro{other} vs.\@ \acro{other}:\acro{other}}

\subsubsection{Xerox/\acro{parc} vs.~OpenFst Label Conventions}

In Xerox/\acro{parc} networks, any identity mapping \emph{c:c} is  
stored as a single \emph{c} label on an arc.  So there is no difference  
between an acceptor network for a language and a network encoding the  
identity relation for that language.\footnote{One of the main reasons
for this Xerox/\acro{parc} convention is to save memory.  Arcs and
	their labels require the
	vast majority of storage for a network, and a single label
	requires less memory than a double label.}  In OpenFst, 
	in contrast, labels  
on arcs are always two-level, visualized as
\emph{input}:\emph{output}, so an acceptor is a special  
case of a transducer wherein each \emph{input}:\emph{output} 
label is an identity  
mapping.  This inherent difference in the way that 
arc labels are stored precludes a straightforward copying of the Xerox
solution in a system based on OpenFst.

\subsubsection{A Semantic Distinction}

There is a semantic complication that needs to be handled, one way or
another, in any implementation that includes the notion of
\acro{other}. In the Xerox/\acro{parc} implementation, Lauri had to make  
a distinction between a two-sided arc label \acro{other}:\acro{other} 
(mapping any \acro{other} symbol to any  
\acro{other} symbol, except itself) and the identity \acro{other}, stored as a
single \acro{other} label, which maps any \acro{other} symbol
to itself (the ``identity mapping'').  In \texttt{(x)fst} regular expressions, plain
\texttt{?} translates into an arc labeled \acro{other} (lamentably printed out as
\texttt{?}), which denotes the identity mapping.  The translation of the 
\texttt{(x)fst} syntax \texttt{?:?} is complex but (significantly) includes an arc labeled
\acro{other:other} (printed out as \texttt{?:?}) \emph{and} an arc
labeled \acro{other} (printed out as \texttt{?}).  The \texttt{?:?} label is the unique case in the
Xerox/\acro{parc} implementation where a potential label like
\emph{c:c} is not reduced to a simple label
\emph{c} on an arc.  Here are some minimal examples:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex c ? t ;
420 bytes. 4 states, 5 arcs, 3 paths. Label Map: Default.
fst[1]: print net
Sigma: ? c t
Size: 3, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   c -> s1.
s1:   ? -> s2, c -> s2, t -> s2.
s2:   t -> fs3.
fs3:  (no arcs)
\end{Verbatim}

\noindent
Note that \emph{c} and \emph{t} are known to this first network, so
the syntactic \acro{any} translates into three arcs from s1 to s2
matching \emph{c}, \emph{t} and \acro{other}, which in this network matches any
symbol other than \emph{c} or \emph{t}.  The translation of syntactic
\texttt{?:?} is rather more complex, as shown here:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex c ?:? t ;
528 bytes. 4 states, 12 arcs, 10 paths. Label Map: Default.
fst[1]: print net
Sigma: ? c t
Size: 3, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   c -> s1.
s1:   ? -> s2, c -> s2, t -> s2, c:t -> s2, c:? -> s2, t:c -> s2, t:? -> s2,
      ?:c -> s2, ?:t -> s2, ?:? -> s2.
s2:   t -> fs3.
fs3:  (no arcs)
\end{Verbatim}

\noindent
In the latter example, note that the arcs from s1 to s2 include an
arc labeled \acro{other}:\acro{other} (printed \texttt{?:?}) 
and a separate arc labeled \acro{other} (printed \texttt{?}); and note all the other arcs that must be generated to translate
the \texttt{?:?} syntax in the regular expression.   The
\acro{other}:\acro{other} arc handles all the other-to-other mappings, except for
identity mappings, while the \acro{other} mapping handles the identity
mappings.  

In the Xerox implementation, note also that an arc labeled
c:\acro{other} (printed \texttt{c:?}), maps an upper-level \emph{c} to
any unknown symbol, and so does not include \texttt{c:c}.  A separate arc labeled just \emph{c} is
required to represent this identity mapping of \emph{c} to \emph{c}.
This can be seen more clearly in the following minimal example.

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: read regex c:? ;
352 bytes. 2 states, 2 arcs, 2 paths. Label Map: Default.
fst[1]: print net
Sigma: ? c
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   c -> fs1, c:? -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
In this example, the regular expression \texttt{c:?}, meaning
\texttt{c}:\acro{any}, is translated into two arcs labeled \emph{c} (for the
identity \texttt{c:c} mapping) and c:\acro{other} (printed \texttt{c:?}), 
for the non-identity mapping.
Later we'll go into why these other arcs are needed and
how they are generated.


\section{Special Symbols in Native OpenFst}

\subsection{Symbols on Arcs are Stored as Integers}

In the Xerox/\acro{parc} implementation, as in OpenFst, the labels on arcs are stored as
integers, but in the Xerox/\acro{parc} implementation these integers are well hidden from
the user.  As delivered, the OpenFst implementation requires the user
to write separate files to define the mapping between integers and
symbols, and that mapping can even be different for the input side
and the output side.\footnote{As these OpenFst symbol-integer
mapping files are limited to \acro{ascii} and cannot even represent
literal spaces, they are not attractive for use with Kleene.  For
Kleene I have devised a new Unicode-friendly \acro{xml} language for
storing networks to file in a text format.}


\subsection{Internal-Only Special Symbols}

In the OpenFst system, the label value 0 is always reserved for epsilon (the
empty string).  The OpenFst algorithms depend on this particular
value, so it must be retained in the Kleene/OpenFst package.
Cyril Allauzen of the OpenFst team informed me by email 29 April 2008 that OpenFst Library has three  
additional special symbols---kRhoLabel, kPhiLabel and kSigmaLabel---that, at present,  
are used internally only, and which bear some very rough resemblance to  
the special \acro{other} symbol in Xerox/\acro{parc} network sigmas.    He describes  
them as ``undocumented/experimental'' symbols.  Responding (generally positively) 
to my own proposal to use a pre-defined
sigma to handle \acro{any} and complementation in Kleene,\footnote{This solution
is seen in the current internal releases of Kleene.} he added:


\begin{quotation}
In your case you might want to use rho [kRhoLabel]. A transition labeled by rho
matches (and consumes) any symbol that does not label a regular transition
at that state. For instance you could implement [\^{}a-z] by an Fst with 3
states: initial, final and sink. Adding a transition labeled by rho from
the initial to the final state, and adding transitions labeled by
\emph{a} to \emph{z}
from the initial state to the non-final sink state.

The benefit is that this would be more compact than fully expanding the
complement. However, there are some issues. rho is only supported by
composition and using determinization and other algorithms on a machine
with rho-transitions would lead to incorrect results.

If you want to use rho-transitions, you need to use `kRhoLabel' as a
label. Observe that FSTs containing transitions labeled by `kRhoLabel'
cannot be written to a file.  To perform composition with rho-transitions,
you need to use

\noindent
ComposeFst\verb!<!Arc\verb!>!(fst1, fst2, ComposeFstOptions\verb!<!COMPOSE\_FST1\_RHO\verb!>!())

\noindent
when `fst1' contains transitions labeled by `kRhoLabel' or

\noindent
ComposeFst\verb!<!Arc\verb!>!(fst1, fst2, ComposeFstOptions\verb!<!COMPOSE\_FST2\_RHO\verb!>!())

\noindent
when `fst2' contains transitions labeled by `kRhoLabel'.

Internally, the library uses this to implement Complement and Difference.
\end{quotation}

\noindent
I deemed these special symbols to be too experimental, and too
limited in implementation, to support
current use in Kleene.\footnote{For future reference, in the OpenFst lib/ directory
these three special symbols are
assigned negative integer values in fst.h, and they are used only in complement.h and
compose.h.  kRhoLabel matched otherwise unmatched labels exiting from a single state;
kPhiLabel was used for some kind of failure transition; and kSigmaLabel ``matches all
labels in alphabet'', though it's still unclear to me how the alphabet is stored or
calculated.} kRhoLabel, for example, is supported/understood only for internal use in the composition
algorithm, and networks containing kRhoLabel cannot even be written to file.

\section{Adding \acro{other} in Kleene?}

\subsection{Kleene as a Layer above OpenFst}

Kleene already provides considerable superstructure above the raw OpenFst library.  It
keeps track of variable bindings in a directed-graph ``environment''
of frames; and
during each Kleene programming session it
maintains a global symbol-integer mapping, which is especially important for
multi-character symbols.\footnote{In Kleene, Unicode characters are automatically mapped to their standard
Unicode code point (integer) values.
Multicharacter symbols are automatically 
stored using arbitrary integer values from the Unicode Private Use Areas
(\acro{pua}), and so the mappings can (and almost always will) vary from one Kleene session to another.
When Kleene networks are stored to file in Kleene's own \acro{xml} text format, 
the syntax necessarily includes the symbol-integer mappings for
multi-character symbols.  When such a network is read
back in from file, perhaps during another session, the
symbol-integer mappings for multi-character symbols
are converted or added, as appropriate, to the
mappings used in the current session.
}  Networks created by OpenFst, and passed back to Kleene as
pointers, are stored in a Java Fst object.  It would, I believe, be entirely possible to
augment the Java Fst object to contain the sigma of each network, including the possibility of
an \acro{other}
symbol similar to the one in \acro{parc} sigmas.  The challenge is to add a new level of
processing in Kleene that detects the presence of \acro{other} symbols and promotes the
sigmas to standardize the meaning of \acro{other} whenever two networks are combined.  This
promotion must be tailored to each operation on networks and may be
non-trivial.

Again, for Kleene and OpenFst, it is not necessarily desirable to
handle \acro{other} as in the Xerox/\acro{parc} implementation; but we
need to understand the issues and devise a solution that is at least
as good.  In what follows, I assume that we will emulate the Xerox/\acro{parc} semantics
as closely as possible.


\subsubsection{Kleene Currently Needs a Pre-Defined Sigma}

In the current 0.9.0.x versions of the Kleene  
language (fall 2009), you need to have the variable  
\$SIGMA pre-defined as a language of single-symbol strings.\footnote{In \acro{sfst}, you similarly  
have to pre-define a variable named \acro{alphabet}.   But in \acro{sfst}, as in  
traditional Two-Level Morphology, the alphabet is a set of upper:lower  
symbol \emph{pairs}.  In the Xerox and OpenFst implementations, the sigma is a set  
of simple symbols.}   When you launch Kleene, it automatically executes 
a global start-up script that includes the line

\begin{Verbatim}[fontsize=\footnotesize]
$SIGMA = [ !-/0-9:-@A-Z[-`a-z{|}~]  ;
\end{Verbatim}

\noindent
using the usual Kleene regular-expression square-bracket syntax that
allows you to list single characters and ranges of characters like
0-9, A-Z and a-z.  I think this global definition covers Latin-1.
This built-in, automatically provided \$SIGMA is provided to allow
users to experiment simply with Kleene ``right out of the box''.
Kleene users can, and should, override this default global definition
with their own definition for any serious usage.

Kleene regular-expression syntax uses  .  (dot) to represent
\acro{any} symbol, 
as in most other regular-expressions syntaxes.

\subsubsection{Problems with a Closed, Pre-defined Sigma}

The requirement to manually pre-define the \$SIGMA (in 
\acro{sfst}, in the current Kleene, and other implementations) is awkward and problematic for users.  This
is one area where I believe the Xerox/\acro{parc} implementation is more sophisticated and
easier to use.  In Kleene syntax, \acro{any} symbol is denoted with . (dot).
Currently, if you define a Kleene network like this

\begin{Verbatim}[fontsize=\footnotesize]
$foo =  .   ;
\end{Verbatim}

\noindent
then you get a network with a start state, a final state, and a
separate arc from the start state to the final state 
for every symbol in the \$SIGMA, and that can add up to a lot of arcs.  
	The resulting network encodes a
	finite language of single-symbol strings with the same
	cardinality as \$SIGMA.  Networks built using
negation/complementation also rely on the pre-defined \$SIGMA and 
typically also end up with a large number of arcs.  

 If you pre-define \$SIGMA and then, in subsequent Kleene regular
 expressions, 
 introduce some symbol not in the \$SIGMA, then all previous networks
 involving .  (dot, representing \acro{any} symbol) or built using
 negation/complementation become invalid or at least incompatible.
 This is a Very Bad Thing.
 
In real-world applications, you cannot assume that the input will be
limited to symbols in your pre-defined \$SIGMA.
Yet you may need to create networks (especially for tokenization) that accept any symbol that might be
thrown at them.  This is easy if, as in the Xerox/\acro{parc}
implementation, you have the built-in notion of an \acro{other}
symbol.

The compilation of alternation rules, at least using the algorithms
that I'm (vaguely) aware of, requires robust negation; so a practical
handling of alternation rules in Kleene will probably rely on a
solid implementation of \acro{other}.


\subsection{Possible Addition of \acro{other} to Kleene}

\subsubsection{Maintaining a Sigma for Each Network}

Kleene represents an OpenFst network by storing a C++ pointer to the underlying
OpenFst network (cast to a
long int) inside a Java object of type Fst (this Java Fst class is something that
I defined myself).  I
assume that Kleene could also maintain a separate sigma for each
network, storing it in the Java Fst object.
When two networks are combined---via concatenation, union,
composition, or whatever operation---or when some unary operation
(such as complementation) is performed on a network, the detection of \acro{other} and
the promotion of sigmas
could be handled at the Kleene level, before calling the
underlying OpenFst functions.

\subsubsection{New Special Symbols for \acro{other}}

In Kleene/OpenFst networks, where labels are always represented as a
two-level pair \emph{input}:\emph{output}, the Xerox solution of
differentiating \acro{other} (printed \texttt{?}) labels from
\acro{other}:\acro{other} (printed \texttt{?:?}) labels is not
possible.

We still need to differentiate
between \emph{identity mapping} and \emph{non-identity mapping}
involving \acro{other}.
So in the context of Kleene/OpenFst I  
propose two special symbols---\acro{other\_id} and
\acro{other\_nonid}---appearing
in  two arc labels:
\acro{other\_nonid}:\acro{other\_nonid} (for non-identity mappings)
vs.\@ \acro{other\_id}:\acro{other\_id} (for identity mappings).  Also possible would be
\acro{other\_nonid}:\emph{c} and \emph{c}:\acro{other\_nonid} labels for known symbols like
\emph{c}; but, I think, 
\acro{other\_id}:\emph{c}, \emph{c}:\acro{other\_id}, \acro{other\_id}:\acro{other\_nonid} and \acro{other\_nonid}:\acro{other\_id} would  
be unnecessary and illegal.
Note that where \emph{c} is known,
\acro{other\_nonid}:\emph{c} and \emph{c}:\acro{other\_nonid} do not include the identity
\emph{c:c}.

The Kleene syntax for \acro{any}, being . (dot), would translate
straightforwardly into \acro{other\_id}:\acro{other\_id}; while the Kleene syntax
.:., for \acro{any}-to-\acro{any}, would translate less trivially into
a set of arcs including two arcs labeled \acro{other\_nonid}:\acro{other\_nonid} and
\acro{other\_id}:\acro{other\_id}.


\section{Preliminary Conclusion}

This is just a first-draft proposal, with a lot of thinking out loud,
but I'm starting to believe that it won't be inordinately difficult
to inject the notion of \acro{other} into Kleene networks, and thus
to remove the requirement (and limitations) of a pre-defined \$SIGMA.

Other possible solutions such as the ``predicate'' labels implemented in the \acro{fsa} library, and
in the Xerox/Grenoble \acro{wfst} library, still require more study.  At this point, I
think that implementing predicates would require significant modification of the
underlying OpenFst library algorithms, which is not realistic in the short- or medium-term.

\newpage
\appendix

\section{Implementation of \acro{other} in Kleene, Assumptions}

In the appendices that follow, I am assuming the following:

\begin{enumerate}

\item
We want to avoid modifying the underlying OpenFst library.
\acro{other} should be handled at the higher Kleene level, and eventually
in Kleene runtime code.  This will greatly facilitate updating to new releases of the OpenFst
library.

\item
Given the fact that OpenFst labels are always two-level, in the form
\emph{input}:\emph{output}, I assume that in Kleene we will need to
distinguish \acro{other\_nonid}:\acro{other\_nonid} vs.\@ \acro{other\_id}:\acro{other\_id},
where \acro{other\_id}:\acro{other\_id} is the identity mapping, and
\acro{other\_nonid}:\acro{other\_nonid} is the non-identity mapping.  We will
also need to handle \emph{c}:\acro{other\_nonid} and \acro{other\_nonid}:\emph{c}, where
\emph{c} is a known character.

\item
The sigma will contain only concrete, known symbols.  \acro{other\_nonid} and \acro{other\_id}
are special labels parallel to epsilon, and like epsilon they will not appear in the sigma.
Each network will store a binary feature, something like \texttt{containsOther}, that will be set to
true if and only if \acro{other\_nonid} and/or \acro{other\_id} is present in the network
labels.\footnote{Instead of \texttt{containsOther}, the feature might be implemented
conversely as \texttt{isOtherFree}.  This is parallel to network features like
\texttt{containsEpsilon} or, conversely,
\texttt{isEpsilonFree}, which mark the presence of the epsilon special character in network labels.}

\item
The integer value 0 (zero) will continue to represent epsilon (the
empty string); the OpenFst algorithms depend on this value.
I assume for now that the value 1 will be reserved for \acro{other\_id}, and
2 will be reserved for \acro{other\_nonid}.  None of these is a valid Unicode
code point value [KRB: recheck this---it might be better to use values from a PUA].

\item
A semantic challenge is that the extension (symbol coverage) of
\acro{other\_nonid} and \acro{other\_id} are the same (the set of all
other/unknown symbols), and for some operations the two symbols need
to be treated as equivalent by the underlying OpenFst algorithms. This means actually conflating the two symbols temporarily, at least
on one side or the other of the network(s), at the Kleene level, before calling the relevant OpenFst
algorithm.  And after the standard OpenFst algorithm returns its result, there may need to be some
``cleanup'' of that result at the Kleene level.

\end{enumerate}

\section{Sketch of an Algorithm for Sigma Promotion}

As the meaning of \acro{other} is network-specific, always to be
understood relative to the concrete symbols that are overtly
``known'' in a network's sigma, the sigmas of two networks must be promoted,
so that the meaning of \acro{other} is aligned, before they can be combined
via union, composition, concatenation or whatever.  

\begin{samepage}
Let the two networks be A and B, with sigma(A) and sigma(B),
respectively.  

\begin{alltt}
{\footnotesize
If network A contains OTHER, then
  for each known symbol \emph{c} in sigma(B) that is not in sigma(A)

    add c to sigma(A)

    for each OTHER_NONID:\emph{o} arc in A
      add a parallel \emph{c}:\emph{o} arc in A

    for each \emph{i}:OTHER_NONID arc in A
      add a parallel \emph{i}:\emph{c} arc in A

    for each OTHER_NONID:OTHER_NONID arc in A
      add a parallel \emph{c}:OTHER_NONID arc in A
      add a parallel OTHER_NONID:\emph{c} arc in A
	  New Oct-Nov 2009: for each x, y in (sigma(B) - sigma(A))
	  	where x != y
		add a parallel x:y arc in A
		add a parallel y:x arc in A

    for each OTHER_ID:OTHER_ID arc in A
      add a parallel \emph{c}:\emph{c} arc in A

If network B contains OTHER, then
  for each known symbol \emph{c} in sigma(A) that is not in sigma(B)

    add c to sigma(B)

    (and add parallel arcs to B on the same model as above)
\normalsize}
\end{alltt}
\end{samepage}

\noindent
After the sigma promotion, other adjustments of the operands may be required,
depending on the operation to be performed (see appendices below).
Dec 2009: This algorithm is currently implemented as expandOtherArcs (in
kleeneopenfst.cc, which is called from copyModifyFirstArgAsNec()
(Java) in the Kleene compiler.

Here is a Xerox example to test the algorithm above.  We will compile three regular expressions
separately:

\begin{enumerate}

\item
a:b

\item
?:?

\item
x:y

\end{enumerate}

\noindent
and then concatenate them together in the order \texttt{((a:b~?:?)~x:y)}, looking at the sigma at each
step.

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: define net1 a:b ;
Defined net1: 340 bytes. 2 states, 1 arc, 1 path. Label Map: Default.

fst[0]: print net net1
Sigma: a b
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   a:b -> fs1.
fs1:  (no arcs)

fst[0]: define net2 ?:? ;
Defined net2: 104 bytes. 2 states, 2 arcs, 2 paths. Label Map: Default.

fst[0]: print net net2
Sigma: ?
Size: 1, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   ? -> fs1, ?:? -> fs1.
fs1:  (no arcs)

fst[0]: define net3 x:y ;
Defined net3: 340 bytes. 2 states, 1 arc, 1 path. Label Map: Default.

fst[0]: print net net3
Sigma: x y
Size: 2, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   x:y -> fs1.
fs1:  (no arcs)

fst[0]: define intermediate a:b ?:? ;
Defined net4: 500 bytes. 3 states, 11 arcs, 10 paths. Label Map: Default.

fst[0]: print net intermediate
Sigma: ? a b
Size: 3, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   a:b -> s1.
s1:   ? -> fs2, a -> fs2, b -> fs2, a:b -> fs2, a:? -> fs2, b:a -> fs2, b:? -> fs2,
      ?:a -> fs2, ?:b -> fs2, ?:? -> fs2.
fs2:  (no arcs)

fst[0]: define final [a:b ?:?] x:y ;
Defined final: 752 bytes. 4 states, 28 arcs, 26 paths. Label Map: Default.

fst[0]: print net final
Sigma: ? a b x y
Size: 5, Label Map: Default
Net: 
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 2
s0:   a:b -> s1.
s1:   ? -> s2, a -> s2, b -> s2, x -> s2, y -> s2, a:b -> s2, a:x -> s2, a:y -> s2,
      a:? -> s2, b:a -> s2, b:x -> s2, b:y -> s2, b:? -> s2, x:a -> s2, x:b -> s2,
      x:y -> s2, x:? -> s2, y:a -> s2, y:b -> s2, y:x -> s2, y:? -> s2, ?:a -> s2,
      ?:b -> s2, ?:x -> s2, ?:y -> s2, ?:? -> s2.
s2:   x:y -> fs3.
fs3:  (no arcs)
\end{Verbatim}


\noindent
Note that the regular expression \texttt{?:?} by itself is
interpreted into a network (here \texttt{net2}) with two states and two arcs labeled
\acro{other} (printed \texttt{?}) and \acro{other:other} (printed \texttt{?:?}).  
In the parallel Kleene/OpenFst package, the labels
will be \acro{other\_id}:\acro{other\_id} and \acro{other\_nonid}:\acro{other\_nonid}, respectively.

\section{The Sigma of the Result Network}

The assignment of the sigma of the resulting network may be
non-trivial, requiring further study.

It appears that the Xerox/\acro{parc} implementation computes the
sigma of the result as the union of the sigmas of the operands.
Even in rather simple examples, not involving \acro{other}, this 
can sometimes result in extraneous symbols being left in the
result sigma, e.g. when \texttt{a:b} is composed with \texttt{b:c}.
The \emph{b} is effectively eliminated in the composition, leaving a
single arc labeled \texttt{a:c}, but \emph{b} remains in the sigma.
It can be eliminated with a call to \texttt{compact~sigma}.

\section{Classic Challenging Operations}

\subsection{Subtraction/Difference and \acro{other}}

The notion of \acro{other} is critical to provide robust  and intuitive 
handling of three operations:
Subtraction, Complementation and Intersection.\footnote{These are
the operations that, in Kleene 0.9.0.5, currently depend on the
manually
predefined \$SIGMA variable.}  The implementation of these three
operations is non-trivial, and it is interesting to note that they are not provided in Perl-like
regular expressions.\footnote{The syntax of Unicode regular expressions provides very limited
subtraction, which can be used only inside symbol sets.  See
\url{http://unicode.org/reports/tr18/}}  
In the first Kleene releases, subtraction and complementation depended on the
manual definition of a special \$SIGMA variable; obviously, depending on the user to
accurately and fully define this \$SIGMA is problematic.

Subtraction, Complementation and Intersection are valid only for
Acceptors and, technically, also for the
special case of \emph{equal-length} Transducers.\footnote{The OpenFst library places other
restrictions on the networks that can be subtracted, complemented and intersected, but these
other restrictions are already accounted for in Kleene and are not affected by the
introduction of \acro{other}.}  In OpenFst, where labels are always
two-level, an Acceptor is a special case of a
Transducer wherein all the \emph{input}:\emph{output} labels represent identity mappings.  At
the Kleene level, where we need to handle \acro{other}, we need to recognize that any network with an
\acro{other\_nonid}:\acro{other\_nonid}, \acro{other\_nonid}:c or c:\acro{other\_nonid} label
is not an acceptor.  (A non-acceptor could still be
an equal-length transducer, and therefore theoretically still subtractable,
complementable and intersectable; but in practice the OpenFst library
algorithms currently require acceptors.)

With the introduction of \acro{other}, and with proper promotion of sigmas, subtraction should now
work without any need for a manually defined \$SIGMA.  Here's a key example, supplied by
Phil Sours:

I consider the case of \acro{any} - \texttt{a}.  In xfst, it is converted into a
single arc with \acro{other}
and the sigma contains \acro{other} and \texttt{a}, so all symbols but \texttt{a} will be
accepted:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: define net1 ? - a;
2 states, 1 arc, 1 path.
fst[0]: print net net1
Sigma: ? a
Size: 2
Net: 3395E0
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   ? -> fs1.
fs1:  (no arcs)
\end{Verbatim}

If I retry that case using an arbitrary symbol \texttt{I} (for \acro{other\_id}) in
place of \texttt{?}
(\acro{other}), I must remember to promote the sigma of the first network
before
performing the subtraction.  Based on the sigma promotion rules in
section B, this
means that the original simple network for \texttt{I} here:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: define net2 I;
2 states, 1 arc, 1 path.
fst[0]: print net net2
Sigma: I
Size: 1
Net: 339740
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   I -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
gets a parallel \texttt{a} arc added to it and has \texttt{a} added to its sigma, i.e.
it is converted into
\texttt{I~|~a} like this:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: define net3 I | a;
2 states, 2 arcs, 2 paths.
fst[0]: print net net3
Sigma: I a
Size: 2
Net: 339690
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   I -> fs1, a -> fs1.
fs1:  (no arcs)
\end{Verbatim}

Now we're ready to do the intrinsic subtraction operation, which
results in:

\begin{Verbatim}[fontsize=\footnotesize]
fst[0]: define net4 net3 - a;
2 states, 1 arc, 1 path.
fst[0]: print net net4
Sigma: I a
Size: 2
Net: 339798
Flags: deterministic, pruned, minimized, epsilon_free, loop_free
Arity: 1
s0:   I -> fs1.
fs1:  (no arcs)
\end{Verbatim}

\noindent
This corresponds exactly to the network and sigma of my first network
above using the intrinsic xfst \texttt{?} (\acro{other}) symbol.  So that case works.
(End of example from Phil Sours.)


We should continue to think about the
special case exemplified in the Xerox \texttt{(x)fst} assignment

\begin{Verbatim}[fontsize=\small]
define net ?:? - ? ;
\end{Verbatim}

\noindent
which involves \texttt{?:?}, which compiles into an equal-length transducer.  This example
somehow works in \texttt{(x)fst}.
The parallel syntax in Kleene would be

\begin{Verbatim}[fontsize=\small]
$net = .:.  - . ;
\end{Verbatim}

[Note to myself:  handle .:.\@ specially in the tokenizer? in the parser?]

\subsection{Complementation and \acro{other}}

Complementation is limited to Acceptors (and, theoretically, to equal-length Transducers) 
and can be reduced
to Subtraction.\footnote{Indeed, in OpenFst the current way to achieve complementation is to use
the Difference() algorithm.}  If \texttt{L} encodes a regular language, then the complement
of \texttt{L}, denoted \texttt{\~{}L}, is generally computed as 
\texttt{Sigma*~-~L}, and ideally computed as \texttt{TheUniversalLanguage~-~L}.  In Kleene-with-\acro{other}, the computation of \texttt{\~{}L} 
would start by compiling the regular expression 

\begin{Verbatim}[fontsize=\footnotesize]
.*
\end{Verbatim}

\noindent
denoting the true Universal Language, not limited to a finite sigma, which would result in a network having one state (both the
start state and a final state), with one arc labeled \acro{other\_id}:\acro{other\_id}
leading from the single state to itself.  Let's call this network A.

The computation of \texttt{\~{}L} would then be \texttt{A~-~L}, and
the algorithm would first have to promote the sigmas of
the two networks as outlined above.  Given a
proper algorithm for sigma promotion, and the standard OpenFst Difference() algorithm,
complementation should just work.

\subsection{Intersection and \acro{other}}

Intersection is limited to Acceptors (and, theoretically, to equal-length Transducers) and can
be reduced to a combination of subtraction and complementation: i.e.\@ 
the intersection \texttt{A~\&~B}
can be computed as \texttt{A~-~\~{}B}, which is equivalent to \texttt{A~-~(.* - B)}.
Again, at the
Kleene level, we need to recognize that any network with an
\acro{other\_nonid}:\acro{other\_nonid}, \acro{other\_nonid}:c or c:\acro{other\_nonid} label is not an Acceptor.

Networks can contain \acro{other\_id}:\acro{other\_id} and still be Acceptors.  With proper sigma promotion,
intersection should just work.


\section{Composition and \acro{other}}

\subsection{Straightforward Composition}

Composition provides the main challenge for Kleene-with-\acro{other}.\footnote{Thanks to Andr\'e
Kempe and Phil Sours for helping me to get this section correct.  Phil has urged me to remove
the inverse cases from the chart, present a simplified algorithm, and then note the
inherent symmetry.  For better or worse, I find it easier to have the cases laid out
explicitly.}
Let's recall that \acro{other\_id}:\acro{other\_id} covers
identity mappings (for unknown symbols) and that
\acro{other\_nonid}:\acro{other\_nonid}, \acro{other\_nonid}:c and c:\acro{other\_nonid} cover \emph{non}-identity mappings.
(The labels \acro{other\_id}:c, c:\acro{other\_id}, \acro{other\_id}:\acro{other\_nonid} and \acro{other\_nonid}:\acro{other\_id} are
anomalous and illegal.)
Labels are visualized as
\emph{input}:\emph{output} in the OpenFst world and as
\emph{upper}:\emph{lower} in the Xerox tradition.

In composition, one must first promote the sigmas and then make
sure that the following arc-level cases are
handled:\footnote{This table does not describe compositions of
entire networks, but rather individual arc-level compositions after the sigmas
of the two networks have been promoted.}

\begin{landscape}
\noindent
{\scriptsize
\begin{tabular}{|lclcl|}
\hline
Original & & First Stage & & Cleaned-up \\
\hline
\hline
OTHER\_ID:OTHER\_ID \_o\_ OTHER\_ID:OTHER\_ID & \verb!=>! & OTHER\_ID:OTHER\_ID & & \\
OTHER\_ID:OTHER\_ID \_o\_ OTHER\_NONID:OTHER\_NONID & \verb!=>! & OTHER\_ID:OTHER\_NONID & \verb!=>! & OTHER\_NONID:OTHER\_NONID \\
OTHER\_ID:OTHER\_ID \_o\_ OTHER\_NONID:c & \verb!=>! & OTHER\_ID:c & \verb!=>! & OTHER\_NONID:c \\
\hline
OTHER\_NONID:OTHER\_NONID \_o\_ OTHER\_ID:OTHER\_ID & \verb!=>! & OTHER\_NONID:OTHER\_ID & \verb!=>! & OTHER\_NONID:OTHER\_NONID\\
OTHER\_NONID:OTHER\_NONID \_o\_ OTHER\_NONID:OTHER\_NONID & \verb!=>! & OTHER\_NONID:OTHER\_NONID & \verb!=>! & OTHER\_NONID:OTHER\_NONID \verb!|! OTHER\_ID:OTHER\_ID\\
OTHER\_NONID:OTHER\_NONID \_o\_ OTHER\_NONID:c & \verb!=>! & OTHER\_NONID:c & & \\
\hline
c:OTHER\_NONID \_o\_ OTHER\_ID:OTHER\_ID & \verb!=>! & c:OTHER\_ID & \verb!=>! & c:OTHER\_NONID\\
c:OTHER\_NONID \_o\_ OTHER\_NONID:OTHER\_NONID & \verb!=>! & c:OTHER\_NONID & &\\
c:OTHER\_NONID \_o\_ OTHER\_NONID:c & \verb!=>! & c:c & & \\
\hline
OTHER\_NONID:c \_o\_ c:d & \verb!=>! & OTHER\_NONID:d & &\\
OTHER\_NONID:c \_o\_ c:OTHER\_NONID & \verb!=>! & OTHER\_NONID:OTHER\_NONID & \verb!=>! & OTHER\_NONID:OTHER\_NONID \verb!|! OTHER\_ID:OTHER\_ID\\
d:c \_o\_ c:OTHER\_NONID & \verb!=>! & d:OTHER\_NONID & &\\
c:OTHER\_NONID \_o\_ OTHER\_NONID:d & \verb!=>! & c:d & &\\
\hline
\end{tabular}
}
\end{landscape}


The underlying challenge, as I see it, is that \acro{other\_nonid} and
\acro{other\_id} must be treated as the same symbol at the intermediate
level, where the languages are intersected.

At the Kleene level, in preparation to 
perform the composition \texttt{A~\_o\_~B}.

\begin{samepage}
\begin{enumerate}

\item
Promote the sigmas of A and B.

\item
At the lower side of A, and the upper side of B, convert all
\acro{other\_id}s to \acro{other\_nonid}\footnote{One could also do the opposite,
converting all \acro{other\_nonid}s to \acro{other\_id}.  The reason is that, at the intermediate level,
\acro{other\_id} and \acro{other\_nonid} must literally be (changed to) the same exact symbol,
having the exact same integer value, so that the standard, off-the-shelf
OpenFst composition algorithm will intersect them.  No information is lost
because the conflation is only
on one side of each network.}

\item
Then call the standard OpenFst Compose() function.

\end{enumerate}
\end{samepage}

\noindent
That is, Kleene would effectively expand \texttt{A~\_o\_~B} to

\begin{Verbatim}[fontsize=\small]
Compose ( promote(A) _o_ OTHER_ID -> OTHER_NONID,
          OTHER_NONID <- OTHER_ID _o_ promote(B)
        )
\end{Verbatim}

\noindent
\begin{samepage}
Then, as a final cleanup of the result network at the Kleene level:

\begin{enumerate}

\item
First, add an \acro{other\_id}:\acro{other\_id} arc parallel to each
\acro{other\_nonid}:\acro{other\_nonid} arc.  [In general? or only for such nodes just created by the
composition.]

\item
Second, convert all \acro{other\_id}:\acro{other\_nonid} and \acro{other\_nonid}:\acro{other\_id} labels to \acro{other\_nonid}:\acro{other\_nonid}.

\item
Third, convert all \acro{other\_id}:c to \acro{other\_nonid}:c, and all c:\acro{other\_id} to
c:\acro{other\_nonid}

\end{enumerate}
\end{samepage}

The resulting network may benefit from sigma simplication, done in the Xerox implemention with the
manually invoked \texttt{compact~sigma} command;


\subsection{Application, Composition and \acro{other}}

\subsubsection{The Formal Mathematical View}

When I talk about \emph{application}, it refers to the application of networks to input, to
produce output.  Application includes \emph{generation}, also known as downward application,
and \emph{analysis}, also known as upward application.
I'm going to make an important distinction between the formal \emph{mathematical} implementation of
application, and the practical commercial implementation of application in Runtime Code.
First the \emph{mathematical} implementation:

When \emph{applying} a network to perform \emph{generation}, the input is 
matched against the upper (OpenFst
``input'') side, and the output is read off the lower (OpenFst
``output'') side.  \emph{Mathematically speaking}, the input is encoded as a finite-state
network, and the matching is
just composition, and the ``reading off the lower side'' is
\emph{mathematically} the extraction
of the lower projection.

\begin{Verbatim}[fontsize=\small]
// Generation
$&Lower_projection( Input _o_ FST )
\end{Verbatim}

\noindent
The language of the lower projection is the set of result strings.

Similarly, applying a network to perform \emph{analysis}, the input is built into a network
and matched against the lower (OpenFst
``output'') side, and the output is read off the upper (OpenFst ``input'') side.  Mathematically,
analysis looks like this:

\begin{Verbatim}[fontsize=\small]
// Analysis
$&Upper_projection( FST _o_ Input)
\end{Verbatim}

\noindent
The extraction of the upper or lower projection is trivial and is already supported in
OpenFst.
If composition is implemented correctly, then application (generation and analysis) should
also just work because, mathematically, the key operation is composition.

\subsubsection{Real-life Commercial Application using Runtime Code}

It is important to make a distinction between the
\emph{mathematical} modeling of application, just shown, and the
\emph{practical} implementation of application in Runtime Code.
Composition, which takes two network arguments and creates a new
network result, is an expensive operation; and, in real-life commercial applications, where
networks are applied thousands and millions of times, implementing
application using composition and projection-extraction would be unacceptably slow.
In commercial production environments, for efficiency,
analysis and generation are usually implemented in low-level Runtime Code, typically written in
C++, in which the
composition (and extraction of a projection) are \emph{simulated}
at low levels; the simulation will need to account for \acro{other\_nonid}
and \acro{other\_id} labels.  

In Runtime Code, a string to be looked up would first be reduced to a vector of integers
representing the symbols (including any multichar symbols) in the string, and the code would directly
traverse the network at the state-and-arc level, matching the input symbols (integers) against
arc labels (also integers), handling weights, epsilons, \acro{other\_nonid} and
\acro{other\_id}, and producing a set of output strings (with their weights).

\section{Determinization and \acro{other}}

OpenFst networks differentiate an Input Side and an Output Side, and
each label is visualized as \emph{input}:\emph{output}.  When you
determinize a network using the OpenFst Determinize(), it's just the
\emph{input} side that gets determinized (so that in the result, no state has
multiple exit arcs with the same input label).  Such one-sided determinization of transducers is usually
called \emph{sequentialization} in the literature.

The labels to worry about during determinization (labels having \acro{other\_nonid} or \acro{other\_id} on the input side) are \acro{other\_nonid}:\acro{other\_nonid},
\acro{other\_nonid}:c and \acro{other\_id}:\acro{other\_id}.\footnote{The labels \acro{other\_id}:c and
\acro{other\_id}:\acro{other\_nonid} are anomalous and illegal.}  For the
standard OpenFst Determinize() to work, we'd first have to convert all
\acro{other\_id}s to \acro{other\_nonid} (or vice versa) on the input side, i.e.\@ Kleene would
effectively expand Determinize(A) to

\begin{Verbatim}[fontsize=\footnotesize]
Determinize( OTHER_NONID <- OTHER_ID _o_ A )
\end{Verbatim}

\noindent
so that there's no distinction between \acro{other\_nonid} and \acro{other\_id} on
the input side before Determinize() is called.  Because the conflation is performed only on
the input side, no information is lost.  The final Kleene-level cleanup of the resulting network
would change any \acro{other\_nonid}:\acro{other\_id} labels in the result back to
\acro{other\_id}:\acro{other\_id}.

With \acro{other\_nonid} and \acro{other\_id} re-separated on the input side, the resulting network is effectively
de-sequentialized again.  
This de-determinization should not matter if other subsequent
operations, notably composition, and any
Runtime Code that simulates composition, are implemented correctly.

\section{Crossproduct and \acro{other}}

The crossproduct operation takes two networks X and Y, which must be Acceptors, and produces a Transducer
that maps every string in X to every string in Y, and vice versa.  At first glance, the presence of a
label \acro{other\_nonid}:\acro{other\_nonid}, \acro{other\_nonid}:c or c:\acro{other\_nonid} is enough 
to disqualify a network as an Acceptor.  If a
network contains \acro{other\_id}, it will appear only as an \acro{other\_id}:\acro{other\_id} label,\footnote{Labels
\acro{other\_id}:c, c:\acro{other\_id}, \acro{other\_id}:\acro{other\_nonid} and \acro{other\_nonid}:\acro{other\_id} are anomalous and
illegal.} 
and such a network should (I think) work with the current Kleene crossproduct
algorithm.\footnote{OpenFst does not offer a crossproduct algorithm off-the-shelf.  With help from Cyril
Allauzen, Lauri Karttunen and Andr\'e Kempe, I implemented crossproduct at the Kleene level,
calling
various OpenFst algorithms.}

\section{\acro{other} and Tokenization for Application}

When a transducer is applied to an input string, that input string first has to be `tokenized for
application', a process that divides the string deterministically into symbols, including multicharacter
symbols.  In practice, the challenge is to keep multicharacter symbols together as one symbol, rather than
exploding them apart.  

This tokenization, in the current Kleene GUI `test' function, collects the multicharacter symbols
that appear in labels on one side of the network (e.g.\@ the lower side when doing analysis), and generates
rules to instantiate a Transliterator (\acro{icu4j}) object that performs the tokenization.  The tokenization
is unreliable in 0.9.0.2 because in cases like \verb!~(.* 'MCS' .*)!, the resulting network does not contain
`MCS' at all.  When \acro{other} is implemented, and each network carries its own sigma, then the rules to
create the Transliterator object must also take into account multicharacter symbols that appear in the sigma
but not necessarily on labels.

\section{Other Operations?}

\subsection{OTHER and Tokenization for Application}

Are there other operations that need to be considered?

\end{document}
