\chapter{Regular Expression Syntax}

\section{Regular Expressions}

In \Kleene{}, regular expressions are the primary way to specify
finite-state machines. The basic \Kleene{} assignment statements have an
\fsm{} variable on the left-hand side and a regular
expression on the right-hand side, e.g.

\begin{alltt}
$var = d ;
$var2 = dog ;
$myvar = (dog|cat|horse) s? ;
$yourvar = [A-Za-z] [A-Za-z0-9]* ;
$hisvar = ([A-Za-z]-[aeiouAEIOU])+ ;
$hervar = (bird|cow|elephant|pig) & (pig|ant|bird) ;
$ourvar = (dog):(chien) \(\circ\) (chien):(Hund) ;
\end{alltt}

\noindent
These regular expressions should already be reasonably familiar to those with experience in
mathematical or programming-language regular expressions.  Don't worry if they are not
yet familiar to you; this chapter will present and explain 
each of the regular-expression operators available in Kleene.

\subsection{Primary Regular Expressions}

Primary regular expressions are recognized directly by the tokenizer and so are
effectively of highest precedence.

\vspace{.5cm}

\renewcommand\tabcolsep{1.25mm}

\noindent
\begin{tabular}{|l|l|}
\hline
\verb!a b c!  & simple alphabetic symbols\\
\hline
\verb!\uHHHH! & \init{bmp} symbol specified by code point value\\
\hline
\verb!\UHHHHHHHH! & supplementary symbol specified by code point value\\
\hline
. & (dot) matches any symbol\\
\hline
\verb!\* \+ \? \. \'! & literalized special characters\\
\hline
\verb!\n \r \t \b \f! & conventional control characters\\
\hline
\verb!'[Noun]' '+Noun'! & single symbols with multi-character names\\
\hline
\verb!$myvar $foo! & names of variables denoting a finite-state machine\\
\hline
\end{tabular}

\vspace{.5cm}

\noindent
Symbols with multi-character names (also known as ``multi-character symbols'') can contain any
Unicode character from the
\init{bmp}\footnote{\url{https://en.wikipedia.org/wiki/Plane_(Unicode)}}
(Basic Multilingual Plane) except for the newline and
carriage return.\footnote{The newline or \unicode{line feed} character has the code
point value \textbackslash{}u000A; the \unicode{carriage return} is \textbackslash{}u000D.}  The
single quotes are delimiters of the multi-character 
name in Kleene syntax and are not part of the name.  If a
multi-character symbol name contains a straight single quote
(\verb!'!), it must be literalized in the syntax with a preceding backslash, e.g.\@
\verb!'[o\'clock]'!.

Symbols with multi-character names are most often used as tags, e.g.\@
\verb!'[Noun]'!, \verb!'[Verb]'!, \verb!'[Adj]'!, \verb!'[Sg]'!,
\verb!'[Pl]'!, \verb!'[1P]'!, \verb!'[2P]'!, \verb!'[3P]'!,
\verb!'[Masc]'! and \verb!'[Fem]'!, that convey categorial,
featural or other grammatical information to a human reader.  In general, any sequence of
\init{bmp} characters can be delimited in single quotes and used as a
single multi-character symbol.  However, it is highly recommended that
the names contain punctuation symbols; that is, it is almost always a
mistake to define multi-character symbols with plain alphabetic names
like \verb!'Noun'!, \verb!'Verb'!, \verb!'sh'! or \verb!'ing'! that, 
minus the single quotes, could be visually confused with a simple
sequence of separate alphabetic symbols.\footnote{In some instances, the
orthography of a language may contain digraphs, trigraphs, etc.\@ that
are always treated as indivisible units, and these might be encoded
safely and usefully as multi-character symbols in a finite-state machine
that models the phonology or orthography of that language.}

Multi-character names starting with \verb!__! (two underscores) or
\verb!**! (two asterisks) are special and are reserved for internal
system use.  Any attempt to define such a multi-character symbol
directly, e.g.\@ \verb!'__foo'!, in your code will cause an exception to be
thrown.

\subsection{Inherently Delimited Regular Expressions}

The following regular expressions are syntactically complex but
inherently delimited with punctuation characters, making them also of highest precedence.

\vspace{0.5cm}

\noindent
\begin{tabular}{|l|p{7.2cm}|}
\hline
\verb![aeiou] [a-z] [A-Za-z0-9]! & character sets (unions)\\
\hline
\verb![^aeiou] [^a-z] [^A-Za-z0-9]! & complemented character sets\\
\hline
\verb!"+" "AT&T" " " "dog"! & double-quoted literalized concatenations of symbols\\
\hline
\verb!<0.5> <0.01> <0.36> <1.0>! &  weights\\
\hline
\verb!$^myfunction!(\textit{args} \ldots) & call to a function returning
an \fsm{}\\
%\hline
%\verb!$@mynetarray![\emph{n}] & reference to an element of an array of
%machines\\
\hline
\end{tabular}

\vspace{0.5cm}

\texttt{[aeiou]} is equivalent to \texttt{(a|e|i|o|u)} and denotes the union of the
symbols \texttt{a}, \texttt{e}, \texttt{i}, \texttt{o} and \texttt{u}.  \texttt{[a-z]},
where the \texttt{-} is a hyphen, denotes the union of a range of characters and is
equivalent to the tediously typed
\texttt{(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z)}.  Unions of character
ranges are always inclusive of the first and last symbols, and the content of the range
is defined by the Unicode encoding.  The first symbol in a range must have a lower
Unicode code point value than the last symbol in the range.  As in Perl regular
expressions, \texttt{[a-ex-zmr]} is equivalent to \texttt{[abcdexyzmr]}.

\texttt{[\^{}aeiou]} is equivalent to \texttt{(. - (a|e|i|o|u))} and denotes the symbol
complement of the union \texttt{(a|e|i|o|u)}.  That is, \texttt{[\^{}aeiou]} denotes any
single symbol \emph{except} \texttt{a}, \texttt{e}, \texttt{i}, \texttt{o} or \texttt{u}.

\texttt{"+"} denotes a literal plus sign---otherwise \texttt{+} is a special character.
(A literal plus sign can also be typed as \texttt{\textbackslash{}+}.)  \texttt{"AT\&T"} is equivalent
to \texttt{(A T "\&" T)}, the concatenation of \texttt{A}, \texttt{T}, a literal
ampersand \& and \texttt{T}.  As already mentioned, spaces are normally ignored in
Kleene regular expressions, and \texttt{"~"} is one way to denote a literal space
symbol.  \texttt{"dog"} denotes the concatenation of \texttt{d}, \texttt{o} and
\texttt{g}, but as none of these characters is special, the double quotes are
extraneous in this case, and so \texttt{"dog"} is equivalent to \texttt{dog} and
\texttt{d o g}.  One way to denote the empty zero-length string (the \emph{epsilon}) is \texttt{""}.

Angle-bracketed expressions like \texttt{<0.5>} represent a weight in the Tropical
Semiring.  The angle brackets can contain a simple literal number, as in this example,
or an arbitrarily complex arithmetic expression (see chapter
\ref{chapt:arithmeticexpressions}).

Functions that return an \fsm{} value have a syntax like
\texttt{\$\^{}nameoffunction(}\emph{args...}\texttt{)}.

\Kleene{} employs a system of
sigils\footnote{\url{http://en.wikipedia/org/wiki/Sigil_(computer_programming)}}
to distinguish identifiers like \verb!$abc! from simple concatenations of symbols 
like \verb!abc!.  A prefixed
\verb!$! marks a variable name with a finite-state-machine value; a prefixed
\verb!$^! marks the
name of a function that returns a finite-state-machine value; and a prefixed \verb!$@! marks the name of
a list of finite-state machines (see chapter \ref{chapt:lists}).

\vspace{0.5cm} 

\begin{center}
\begin{tabular}{|l|p{8cm}|}
\hline
\verb!abc! & the concatenation of the three separate symbols \emph{a}, \emph{b} and \emph{c} \\
\hline
\verb!$abc! & a variable named \verb!$abc! \\
\hline
\verb!$^abc!(\textit{args}\ldots{}) & a function named
\verb!$^abc! that returns a finite-state-machine value\\
\hline
\end{tabular}
\end{center}

\vspace{0.5cm}

It is important to note the distinction between a single-quoted
multi-character symbol like \verb!'[Noun]'!, which denotes a single
symbol with the multi-character print name \verb![Noun]!, versus a
double-quoted string like \verb!"dog"!, which denotes the concatenation of
the individual symbols between the quotes: \texttt{d} followed by \texttt{o} followed by
\texttt{g}.  A double-quoted string can
contain any Unicode \init{bmp} symbol except for newline and
carriage-return.\footnote{The newline or \unicode{line feed} character is
\textbackslash{}u000A; the \unicode{carriage return} is
\textbackslash{}u000D.}

A closed set of control characters can appear inside double-quoted strings,
and in normal regular-expression text,
represented using backslash conventions that will be familiar to many
programmers.

\vspace{0.5cm} 

\begin{center}
\begin{tabular}{|c|c|l|}
\hline
\textbf{Syntax} & \textbf{Code Point Value} & \textbf{Character Name} \\
\hline
\hline
\textbackslash{}n & 0xA & \charname{line feed}
(\charname{lf}) or
``newline''\\
\hline
\textbackslash{}r & 0xD & \charname{carriage return}
(\charname{cr})\\
\hline
\textbackslash{}t & 0x9 & \charname{character tabulation} or
``tab''\\
\hline
\textbackslash{}b & 0x8 & \charname{backspace} \\
\hline
\textbackslash{}f & 0xC & \charname{form feed}
(\charname{ff}) \\

\hline
\end{tabular}
\end{center}

\vspace{0.5cm}

\noindent
For examples of the use of such special characters, and limitations on
writing finite-state machines 
containing such characters to \init{xml}, see
Appendix~\ref{app:controlcharacters}.

\subsection{Regular-Expression Operators}

The following regular expression operators are available, 
listed from high to low precedence.

\vspace{0.5cm}

\noindent
\begin{tabular}{|l|l|l|l|}
\hline
( ) &  parenthetical grouping & circumfix &\\
\hline
\verb!* + ? {2} {2,4} {2,}! & iteration & postfix &\\
\hline
: & crossproduct & infix &\\
\hline
\verb!~!  & complement/negation & prefix & \\
\hline
(no overt operator) & concatenation & juxtapose & left assoc.\\
\hline
\verb!-! & subtraction  & infix & left assoc.\\
\hline
\verb!&! & intersection & infix & left assoc.\\
\hline
\verb!|! & union        & infix & left assoc.\\
\hline
(various rule operators) & & &\\
\hline
$\circ$ \emph{or} \_o\_  & composition & infix & left assoc.\\
\hline
\end{tabular}

\vspace{0.5cm}

Parenthesized expressions have the highest priority, and so parentheses can
be used to force desired groupings, overriding other default
precedences.

Postfixed iteration operators have the next highest precedence.
The postfixed \texttt{*}, sometimes called the Kleene star, denotes zero
or more repetitions of the previous expression.  Similarly, the
postfixed \texttt{+} (the Kleene plus) 
denotes one or more of the previous expression.
The postfixed question mark \texttt{?} indicates that the previous
expression is optional; thus \texttt{a?} is equivalent to \texttt{(a |
"")}, the union of \texttt{a} and the empty string.  The postfixed
\texttt{\{2\}} indicates the concatenation of two of the previous
expression; e.g., \texttt{a\{2\}} is equivalent to \texttt{aa}.
\texttt{a\{2,4\}} denotes 2 to 4 concatenations of \texttt{a}, and
\texttt{a\{2,\}} denotes 2 or more concatenations of \texttt{a}.

The : is the cross-product operator, used in examples like \texttt{a:b},
\texttt{s:z}, \texttt{(book):(books)} and \verb!$fst1:$fst2!.  The
operands must denote regular languages (not regular relations), and the
result is a relation that relates each string in one language to all the
strings in the other language.  Because : has higher precedence than
concatenation, note that a regular expression written \texttt{ab:cd} is
equivalent to \texttt{a(b:c)d}.

The prefixed \texttt{\~{}} denotes the language complement of the
following expression.  For example, \texttt{\~{}a} is equivalent to
\texttt{(.* - a)}, i.e., the universal language minus the string
\texttt{a}.  The expression following \texttt{\~{}} must denote a
regular language (not a regular relation).  The arguments to the infixed
subtraction and intersection operators, \verb!-! and \verb!&!, must also
denote regular languages.

The union operator, \verb!|!, works with arguments that denote both
regular languages and regular relations.

The composition operator, typed either as $\circ$ or its \acro{ascii}
equivalent \texttt{\_o\_}, where the \texttt{o} in \texttt{\_o\_} is the
lowercase \texttt{o} letter, will be explained below.

The \texttt{(}, \texttt{)}, \texttt{:}, \texttt{*}, \texttt{+},
\texttt{?}, \texttt{\~{}}, \texttt{-}, \texttt{\&} and $\circ$ are all
special characters, and they can be literalized (un-specialized) in the
usual Kleene ways; e.g., a literal asterisk can be typed as
\texttt{"*"}, \verb!\*!, or \verb![*]!.

\subsection{Precedence Issues}
 
The relative precedence of  \verb!:!, \verb!~!, and the various postfix
iteration operators could still be debated, and it will probably never be
possible to please everyone.
Currently in Kleene, 
\verb!a:b*!  is equivalent to \verb!a:(b*)!,\footnote{This is a
departure from the precedence in the Xerox xfst language, where
\verb!a:b*! is interpreted as \verb!(a:b)*!.  The historical
justification for that interpretation harked back to the earlier Xerox twolc
language, wherein the alphabet was not a set of letters like \verb!a!,
\verb!b! and \verb!c!, but rather a set of ``concrete pairs'' like
\verb!a:a!, \verb!a:b!, \verb!s:z!, etc. To those already familiar with
twolc, wherein \verb!a:b! was an indivisible alphabetic unit, it seemed
natural to interpret \verb!a:b*! as \verb!(a:b)*!. As the twolc language
later fell into complete disuse at Xerox, and as alphabets of concrete
pairs play no part in Kleene, the argument for interpreting
\verb!a:b*! as \verb!(a:b)*! now lacks appeal.}
\verb!a*:b!  is equivalent to \verb!(a*):b!,
\verb!a*:b*! is equivalent to \verb!(a*):(b*)!,
and
\verb!$^invert(a*:b*)! is equivalent to \verb!b*:a*!.
The notation \verb!~.*! is
equivalent to \verb!~(.*)! and so denotes the empty language.
Note also that \verb!~a:b! is
equivalent to \verb!~(a:b)!, which is semantically illegal.\footnote{In
	general, transducers are not closed under complementation, so
	\texttt{\~{}T}, where \texttt{T} is a transducer, causes a runtime
exception in \Kleene{}, much like division by zero in arithmetic
expressions.}

By long tradition, concatenation has higher precedence
than union and intersection, so one can write  

\begin{Verbatim}
$foo = dog|cat|mouse ; 
\end{Verbatim}

\noindent
to mean

\begin{Verbatim}
$foo = (dog)|(cat)|(mouse) ;
\end{Verbatim}

\noindent
Following other programming languages, \verb!&! has slightly higher
precedence than \verb!|!.\footnote{Similarly in most other languages,
\texttt{\&\&}, the Boolean \emph{and},
has slightly higher precedence than \texttt{||}, the Boolean \emph{or}.}
The precedence of subtraction (\verb!-!) relative to intersection
(\verb!&!) is still debatable, but it should probably be higher than
union (\verb!|!).
Rules are typically composed together, so composition is given lower precedence
than the various operators used to construct rules (see chapter
\ref{chapt:alternationrules}).  

The use of
parentheses, even when formally unnecessary, to explicitly show groupings can
often improve the human readability of your source code.

\subsection{Unicode and Kleene}

Unicode is embraced from the beginning in the Java/Swing \acro{gui}, and users are
encouraged, though not required, to edit their script files using a Unicode-capable text
editor.\footnote{In the dark days before Unicode, writing applications for Russian,
	Greek, Georgian, etc.\@ too often used to require or encourage the use of Roman
	transliterations, which are problematic and irksome.  \Kleene{} has a Java-language parser, and so
	is able, using normal Java features, to read a file in almost any standard encoding
	and convert it to Unicode.  Unless told otherwise, \Kleene{} (like Java) assumes that a file
	being read is in the default encoding of the host operating system (as detected by
Java) and will convert it to Unicode accordingly.  Kleene also provides ways, described
below, to read script files in any encoding that you designate.}  Unicode characters can also be
indicated in the syntax using the familiar Java-like \verb!\u!HHHH escape sequence,
i.e., \verb!\u! followed by exactly four hex digits: 0-9, a-f or A-F.  For
supplementary Unicode characters, Kleene recognizes the Python-like \verb!\U!HHHHHHHH
escape sequence, i.e., uppercase \verb!\U! followed by exactly eight hex digits; and
for any Unicode character, Kleene also recognizes the \verb!\U{H...}! notation, which
contains one or more hex digits between the curly braces.

Kleene source files are typically Unicode files, and may contain code or comments
containing arbitrary Unicode characters; so in Unicode files
the \verb!\u!  sequence must be
followed by exactly four hex digits, even inside comments.\footnote{Whatever
the encoding of a Kleene source file might be, when it is read in, tokenized
and parsed by Kleene, it is converted, one way or another, into Unicode.  This
is standard behavior for Java programs, which handle text internally as
String objects, which are always Unicode strings.}

Kleene also provides a function \verb!$^charForCpv(#num)!, aliased as \verb!$^cpv2char(#num)!, which takes an arbitrarily
complex arithmetic expression (see chapter \ref{chapt:arithmeticexpressions}) as its argument
and returns a character symbol.  There is also a function \verb!#^getIntCpv($char)!, aliased as
\verb!$^char2cpv($char)!, that takes a one-symbol regular expression and returns the code point value as a
number.  The following expressions are all equivalent:

\begin{Verbatim}
$fsm = a b c ;
$fsm = a b \u0063 ;             // hexadecimal 63 is the code 
                                //   point value for c
$fsm = a b $^charForCpv(0x63) ; // 0x63 is the hex _number_ 63
$fsm = a b $^charForCpv(99) ;   // decimal 99 = hexadecimal 0x63
$fsm = a b $^cpv2char(0x63) ;
$fsm = a b $^cpv2char(99) ;

$fsm = a b $^cpv2char(0x62 + 1) ;
$fsm = a b $^cpv2char(98 + 1) ;
$fsm = a b $^cpv2char(100 - 1) ;
$fsm = a b $^cpv2char(#^char2cpv(a) + 2) ;
\end{Verbatim}

\noindent
Note that the argument to \verb!$^cpv2char(#num)! is an arbitrarily complex 
\emph{arithmetic} expression, not a regular expression;
and in an arithmetic expression, the plus sign \verb!+! denotes simple arithmetic addition, not one or more
iterations like the Kleene-plus in a regular expression.  Similarly, inside an
arithmetic expression, the hyphen \texttt{-} denotes normal arithmetic subtraction.


\subsection{Weights}

\subsubsection{The Tropical Semiring}  

Kleene can be used to build finite-state machines that are weighted or unweighted.
The current implementation of weights is limited to the
Tropical Semiring, which is the default semiring of the OpenFst library, and no doubt
the most useful semiring for linguistic applications.
In the Tropical Semiring

\begin{itemize}
\item
The weights are floating-point logarithmic \emph{costs}, to be explained below.
\item
The \emph{extension} operation that accumulates weights along a single
path, to calculate the weight of the whole path, is simple arithmetic addition.\footnote{In OpenFst, the extension operation of
each
semiring is abstractly called \texttt{Times()}.}
\item
The \emph{collection} operation for combining the weights of multiple
paths is \texttt{min}.\footnote{In OpenFst, the collection
operation of each semiring is abstractly called \texttt{Plus()}.}
Thus, among multiple solutions, the one with the minimum cost is preferred.
\item
As the extension operation is simple addition, the neutral weight for extension is 0.0.  
\item
As the collection operation is \texttt{min}, the neutral weight for collection is infinity ($\infty$).
\end{itemize}

\noindent
Where \texttt{p} is a probability ranging from 0.0 (impossible) to
1.0 (certain), the cost is calculated as -\emph{log}\texttt{(p)},
such that 0.0 probability corresponds to infinite cost, and 1.0
probability corresponds to a cost of zero.
In Kleene regular-expression syntax, weights are denoted within angle brackets,
e.g.\@ \texttt{<0.1>} and \texttt{<0.9>}.  The angle brackets can contain any
arbitrarily complex arithmetic expression (see chapter
\ref{chapt:arithmeticexpressions}).

Each arc and each final state in a finite-state machine has a weight.  An unweighted
machine in Kleene is one in which all the weights are the neutral weight 0.0.

If you visualize the weights as costs calculated from probabilities, where each
probability \texttt{p} ranges from 0.0 (impossible) to 1.0 (certain), and each cost
\texttt{c} is calculated as \texttt{-log(p)}, then all the costs will be non-negative,
ranging from 0.0 (no cost) to positive infinity (infinite cost).  However, the Tropical
Semiring in Kleene (from OpenFst) is defined such that the costs can range from negative
infinity to positive infinity, thus permitting negative costs.  As will be shown below,
negative costs can sometimes be useful in pattern-matching applications.

If the programmer tries to
denote negative weights straightforwardly as, for example, \@ \texttt{<-0.1>}, this
creates a problem for the Kleene tokenizer, which recognizes the
sequence \texttt{<-} as a left arrow, used in alternation rules, which
will be presented in chapter \ref{chapt:alternationrules}.
The workarounds for this problem, in the rare cases where negative
weights might be required,
are to

\begin{enumerate}
\item
Put whitespace between the \texttt{<} and \texttt{-}, i.e.\@
\texttt{< -0.1>}, or
\item
Put parentheses around the negative cost value, i.e.\@
\texttt{<(-0.1)>}
\end{enumerate}

\noindent
If the programmer types \texttt{<-0.1>}, Kleene generates a
ParseException and, in the \acro{gui}, prints a message showing how
to fix the syntax.

The use of the Tropical Semiring, with cost weights, has practical computational
advantages,\footnote{In the classic probability semiring, the weights are probabilities, and the extension
operation, which combines the weights along a single path, is multiplication.  Probabilities tend to be very small numbers, and when they are multiplied
together, precision is lost.  In the Tropical Semiring, where the weights are converted to costs, and the
extension operation is addition, the precision problem is avoided.  Also, computers traditionally
performed addition more efficiently than multiplication, but this may not be true in modern computers.} but programmers are much more likely to think in terms of
probabilities (0.0 to 1.0) or percentages (0 to 100).  Kleene supports functions that return arithmetic
values (see chapter \ref{chapt:arithmeticexpressions}), including \verb!#^prob2c(#num)!,
which takes an argument representing a probability
(0.0. to 1.0) and returns the cost; and \verb!#^pct2c(#num)!, which takes an argument
representing a percentage
(0 to 100) and returns the cost.  These functions can be used inside the angle brackets, e.g.


\begin{Verbatim}
$fst = c  ( a <#^prob2c(.5)> 
          | u <#^prob2c(.4)> 
          | o <#^prob2c(.1)> 
          ) t ;
\end{Verbatim}

\noindent
or

\begin{Verbatim}
$fst = c  
       ( a <#^pct2c(50)> | u <#^pct2c(40)> | o <#^pct2c(10)> ) 
       t ;
\end{Verbatim}

\noindent
to reflect that intuitive notion that ``cat'' occurs 50\% of the time, ``cut'' 40\% of the time, and ``cot''
10\% of the time.


\subsection{Whitespace in Regular Expressions}
 
Whitespace is ignored in Kleene regular expressions unless it is
literalized.  The following statements are equivalent, each denoting the
simple concatenation of the \texttt{d}, \texttt{o} and \texttt{g}
characters because the
spaces in the regular expressions are simply ignored:

\begin{alltt}
$foo = dog ;
$foo = do g ;
$foo = d og ;
$foo = d o g ;
\end{alltt}

\noindent
Spaces and other whitespace characters can be inserted anywhere between operators and operands in Kleene regular
expressions, and such whitespace often improves human readability.  In the following examples,
literal spaces are displayed as \verb*! ! for clarity. 

A space in a regular expression can be literalized in three ways:

\begin{enumerate}
\item
Putting the literalizing backslash directly before the space, i.e.\@ \verb*!\ !
\item
Putting the space inside square-bracketed symbol unions \verb![!\ldots\verb!]! or
\verb![^!\ldots\verb!]!, e.g.\@ \verb*![ abc]! matches \verb!a!,
\verb!b!, \verb!c! or a literal space, or
\item
Putting the space inside double quotes, e.g.\@ \verb*!" "! and
\verb*!"John Smith"!
\end{enumerate}

\noindent
For example, the following assignments are all equivalent, each containing two literal
spaces:

\begin{alltt}
$fsm = to\textbackslash{}\verb*! !and\textbackslash{}\verb*! !fro ;
$fsm = t o \textbackslash{}\verb*! !  a n d \textbackslash{}\verb*! !  f r o ;
$fsm = to \textbackslash{}\verb*! !  and \textbackslash{}\verb*! !  fro ;
$fsm = to "\verb*! !" and "\verb*! !" fro ;
$fsm = "to\verb*! !and\verb*! !fro" ;
$fsm = to [\verb*! !] and [\verb*! !] fro ;
\end{alltt}

\noindent
A language of strings that start with a lowercase letter \texttt{a}-to-\texttt{z} and continue with
any number of lowercase letters \emph{or spaces} can be defined as

\begin{alltt}
$fsm = [a-z] [a-z\verb*! !]* ;
\end{alltt}

\noindent
Note that the second square-bracketed character set expression, \verb*![a-z ]!, contains a
literal space.

The Kleene treatment of whitespace in regular expressions is
similar to the way that whitespace is ignored in arithmetic
expressions, and it is like Perl regular expressions marked with the /x
suffix.\footnote{There are similar options in Python and Java to allow
you to insert whitespace inside regular expressions to make them more
readable for human beings.}

\subsection{Denoting the Empty String}

The empty (zero-length) string can be represented in various
equivalent ways,
including the Unicode U+03F5 \unicode{greek lunate epsilon symbol}
$\epsilon$,\footnote{This
Unicode character can be typed into the Kleene \acro{gui}, using
standard Java Input Methods, including the CodePoint Input
Method, and into any Kleene script prepared with a
Unicode-capable text editor.  The Unicode Standard 
specifies that U+03F5 \unicode{greek lunate epsilon symbol}
is for
use in mathematical formulas, such as regular expressions, and
is not to be used in normal Greek text, where U+03B5 
\unicode{greek small letter epsilon} is appropriate.}  
the Unicode escape sequence \verb!\u03F5!,
the \acro{ascii} sequence \verb!_e_!,
an empty double-quoted string \verb!""!, 
\verb!a? - a!, etc.  The global start-up script also defines
the variables \verb!$e! and \verb!$eps! as the empty string.  The 
following examples are all equivalent, denoting a relation with \texttt{a} on the
upper side related to the empty string on the lower side:

\begin{alltt}
$foo = a:\(\epsilon\) ;
$foo = a:\(\backslash\)u03F5 ;
$foo = a:_e_ ;
$foo = a:"" ;
$foo = a:$e ;
$foo = a:$eps ;
\end{alltt}

\subsection{Denoting Any Symbol}

In Kleene regular expressions, the \verb!.! (dot) syntax by itself is a wildcard
that denotes any symbol in an acceptor or, in a transducer, the mapping of
any possible symbol to itself. The \verb!.:.! syntax denotes the mapping of
any possible symbol to any possible symbol, including itself.  The .\@ therefore covers \emph{a}:\emph{a},
\emph{b}:\emph{b}, \emph{c}:\emph{c}, etc., but not \emph{a}:\emph{b} or
\emph{b}:\emph{a}; while .:.\@
covers  \emph{a}:\emph{a},
\emph{b}:\emph{b}, \emph{c}:\emph{c}, etc., plus \emph{a}:\emph{b}, \emph{b}:\emph{a}, etc.

\begin{Verbatim}
$v = . ;   // any symbol, or map any symbol to itself
\end{Verbatim}

\begin{alltt}
$w = .:. ; // map any symbol to any symbol, including itself
\end{alltt}

\noindent
The Kleene \verb!.! really represents \emph{any}
possible symbol---including simple and multi-character symbols---or the mapping of any character to itself, and is not limited to some
finite alphabet pre-defined by the programmer.\footnote{The Kleene \verb!.! is like the
\verb!?! in the Xerox Finite State Toolkit.}

The semantics of the special .\@ (dot or period) is quite complex, being
interpreted into \fsm{}s 
that match \specsym{other}, also known as unknown, symbols, and this subject is treated in
more detail in Appendix~\ref{app:other}.  Luckily, the Kleene interpreter takes care of this, and
the programmer doesn't
have to worry about the underlying complexity.

To denote a literal dot (a period) in a regular expression, use the
backslashed \verb!\.! or the double-quoted
\verb!"."!, or put the dot inside a square-bracketed symbol-union
expression.  Once again, literalized spaces are shown in the following examples as \verb*! !.

\begin{alltt}
$fsm = T h e \textbackslash{}\verb*! ! e n d \textbackslash{}. ;
$fsm = "The\verb*! !end." ;
$fsm = The "\verb*! !" end "." ;
$fsm = T h e [\verb*! !] e n d [.] ;
\end{alltt}

\section{Abstraction Mechanisms}

\subsection{Variables}

As previously explained above, variables having a finite-state machine value are distinguished
syntactically with a \verb!$! sigil, and they can appear on the
left-hand side of an assignment statement.

\vspace{.2cm}
\noindent
\$\emph{variableName} = \emph{RegularExpression} ;
\vspace{.2cm}

\noindent
The regular expression can continue over any number of lines, and the
assignment statement is terminated with a semicolon.  Once variables 
such as \verb!$foo! and \verb!$bar! have been bound to \fsm{} values,
they can appear as operands in subsequent regular expressions.

\begin{alltt}
$foo = dog | cat | elephant | zebra ;  // bind $foo
$bar = bat | dog | octopus | frog ;    // bind $bar

// refer to and use the values of $foo and $bar
//    in a subsequent regular expression
$result = ($foo | $bar) - (elephant | bat) ;
\end{alltt}

\noindent
In this example, the resulting \fsm{} would encode the language
consisting of the strings \emph{dog}, \emph{cat}, \emph{zebra},
\emph{octopus} and \emph{frog}.  (The \fsm{} could also be viewed and used as an
identity transducer that maps each of these words to itself.)  A reference to an
unbound variable inside a regular expression
raises a runtime exception, from which the interactive Kleene \gui{} can recover.

Because finite-state machines can get very large, copying is avoided.
The following sequence of assignment statements results in \verb!$var2! being an alias, bound to
the same \fsm{} object as \verb!$var1!.

\begin{Verbatim}
$var1 = a*b+[A-Za-z0-9]{3} ;
$var2 = $var1 ; // $var2 and $var1 are now bound 
                //   to the same FST
\end{Verbatim}

\subsection{Pre-defined Functions}

\subsubsection{Regular Operations}

Rather than inventing and proliferating new regular-expression operators, 
the \Kleene{} design philosophy is to give access to some operations via
pre-defined functions, including

\begin{description}
\item[]
\verb!$^invert!(\textit{regexp})
\item[]
\verb!$^reverse!(\textit{regexp})
\item[]
\verb!$^inputProj!(\textit{regexp}) or \verb!$^inputside!(\textit{regexp}) or \verb!$^upperside!(\textit{regexp})
\item[]
\verb!$^outpuProj!(\textit{regexp}) or \verb!$^outputside!(\textit{regexp}) or \verb!$^lowerside!(\textit{regexp}) 
\item[]
\verb!$^rmWeight!(\textit{regexp})
\item[]
\verb!$^copy!(\textit{regexp}) 
\end{description}

\noindent
Names of functions that return an \fsm{} value are preceded with the \verb!$^! sigil.
Note that \verb!$^inputProj()!, \verb!$^inputside()! and \verb!$^upperside()! are equivalent, where the
``input'' terminology reflects the OpenFst visualization of an \fst{}, and the
``upper'' terminology reflects the Xerox visualization.  The same holds for
``output'' (OpenFst) and ``lower'' (Xerox). 

A function call that returns an \fsm{} value is a \Kleene{} regular
expression and can, just like a variable having an \fsm{} value,
appear as an operand inside a larger regular expression.  Note that while

\begin{alltt}
$var2 = $var1 ;
\end{alltt}

\noindent
simply makes \verb!$var2! an alias for \verb!$var1!, binding \verb!$var2! to the
same \fsm{} as \verb!$var1!,

\begin{alltt}
$var2 = $^copy($var1) ;
\end{alltt}

\noindent
creates a deep copy of the \fsm{} referenced by \verb!$var1! and binds
\verb!$var2! to that deep copy.

The functions presented above do not destroy or modify their arguments, thus

\begin{Verbatim}
$orig = (dog):(chien) ;
$new = $^lowerside($orig) ;
\end{Verbatim}

\noindent
leaves \verb!$orig! intact while setting \verb!$new! to a new \fsm{}
that encodes the language consisting only of the string
\emph{chien}.  

The following \emph{destructive} functions, which operate on
an \fsm{} in place, have also been defined:

\begin{description}
\item[]
\verb!$^invert!!(\emph{regexp})
\item[]
\verb!$^inputside!!(\emph{regexp}) or \verb!$^upperside!!(\emph{regexp}) 
\item[]
\verb!$^outputside!!(\emph{regexp}) or \verb!$^lowerside!!(\emph{regexp}) 
\item[]
\verb!$^rmWeight!!(\emph{regexp})
\end{description}

\noindent
Note that the names of destructive functions end with an
exclamation mark to mark them as dangerous.\footnote{There is no magic 
to the exclamation mark,
and simply adding one to the end of a function name does not make the function
destructive.}  After executing the following example

\begin{Verbatim}
$orig = (dog):(chien) ;
$new = $^invert!($orig) ;
\end{Verbatim}

\noindent
both \verb!$orig! and \verb!$new! would be bound to the same
modified \fsm{}, with \emph{chien} now on the input (upper) side, and \emph{dog} on
the output (lower) side.  Such behavior is dangerous, not generally recommended, and the use of these
destructive functions is recommended only for experts working at the limits
of memory.

While Unicode code point values are integers, and Kleene does handle basic
arithmetic expressions involving integers and floating-point numbers (see chapter
\ref{chapt:arithmeticexpressions}), it is important to understand
that Kleene makes a clear distinction between regular expressions and arithmetic expressions.
A Unicode character like \texttt{b}, though it has an integer code point value of hexadecimal 62, is
not, for Kleene, the same as the integer value.  We have already presented the \verb!\u0062! notation,
which is a regular expression and denotes the Unicode character \texttt{b}.  In contrast, in Kleene arithmetic
expressions, the hexadecimal number 62 is denoted as \texttt{0x62}.  

\subsection{User-defined Function Syntax}

\subsubsection{Simple Examples}

Users can also declare and call their own functions.  As a minimal and admittedly
trivial example, consider the
\emph{function definition}

\begin{Verbatim}
$^myunion($a, $b) {
    return $a | $b ;
}
\end{Verbatim}

\noindent
which defines \verb!$^myunion! as a function that takes two \fsm{} arguments, represented here by the formal
parameters \verb!$a! and \verb!$b!, unions them together, and returns the \fsm{} result.  Note that the formal
parameters are marked as being of type \fsm{} by their \verb!$! sigils.  Function names (of all types) 
in Kleene are always
prefixed with the \verb!^! prefix, and the \verb!$^! prefix, as in \verb!$^myunion!, marks this as a function
that
returns an \fsm{} value.  Once defined, our new function can be called just like a pre-defined Kleene function:

\begin{Verbatim}
$foo = dog|cat|rat ;
$bar = elephant|horse|bird ;

$newfsm = $^myunion($foo, $bar) ;
// equivalent to $newfsm = $foo | $ bar ;
\end{Verbatim}

\noindent
When a function is called, the arguments can be arbitrarily complex expressions, as long as they evaluate to a
value of the type required by the function.

\begin{Verbatim}
// call $^myunion with complex regular-expression arguments
$newfsm = $^myunion(worm | dog | rabbit | fox, 
                    skunk | cat | hippopotamus) ;
\end{Verbatim}

\noindent
In addition, for a function like \verb!$^myunion()! that returns an \fsm{}, a call to \verb!$^myunion()! is
itself a regular expression and can appear anywhere a regular expression is legal.

\begin{Verbatim}
$newfsm = $^myunion(worm | dog | rabbit | fox, 
          $^myunion(skunk, $^myunion(cat, hippopotamus)) ) ;
\end{Verbatim}

\subsubsection{Practical Example}

As a much more practical function-definition example, consider the operation of \emph{priority union}, which is defined as follows:

\begin{quotation}
Let Q and R be transducers.  The priority union of Q and
R, giving \emph{input-side} priority to Q, returns the union of Q and R
with the added 
restriction that if both Q and R share an input string \emph{i}, then
the result transducer contains only the paths from Q that have
\emph{i} on the
input side.
\end{quotation}

\noindent
Priority union with \emph{output-side} priority is also potentially useful.
In \Kleene{} these functions can be defined as

\begin{Verbatim}
$^priority_union_input($q, $r) {
	return $q | (~$^inputside($q) _o_ $r) ;
}

$^priority_union_output($q, $r) {
	return $q | ($r _o_ ~$^outputside($q)) ;
}
\end{Verbatim}

\noindent
Such function \emph{definitions} are equivalent to the following function
\emph{assignments}, which have just a function variable on the left-hand side, followed by an equal sign
and an \emph{anonymous function} on the right-hand side, which most users will find less
friendly.\footnote{Lisp and Python programmers
will recognize anonymous functions as ``lambda'' functions.  Anonymous functions are important in the Scala
and Clojure languages, and have recently been added to Java 8.}  

\begin{Verbatim}
$^priority_union_input = $^($q, $r) {
	return $q | (~$^inputside($q) _o_ $r) ;
} ;

$^priority_union_output = $^($q, $r) {
	return $q | ($r _o_ ~$^outputside($q)) ;
} ;
\end{Verbatim}

\noindent
The anonymous-function expressions

\begin{Verbatim}
$^($q, $r) { return $q | (~$^inputside($q) _o_ $r) ; }
\end{Verbatim}

\noindent
and

\begin{Verbatim}
$^($q, $r) { return $q | ($r _o_ ~$^outputside($q)) ; }
\end{Verbatim}


\noindent
look just like function definitions, but they begin with the \verb!$^! sigil followed directly
by the parameter list. So an anonymous function in Kleene is one that has a function sigil but 
no name.  The \verb!$^! sigil, as always in Kleene,
indicates that these functions return an \fsm{}, and the
parameter list, here \verb!($q, $r)!, indicates that the functions take two \fsm{} arguments.  We will find
uses for anonymous functions later, but for now we will restrict ourselves to the arguably friendlier function
definitions.

Priority union can be useful in morphology to override regular but incorrect
forms with their correct irregular forms.  For example, assume that
an \fsm{} named \verb!$productive_english! has been productively generated to contain
input$\Longleftrightarrow$output
string pairs like the following (where \verb![Verb]! and \verb![Past]! are
multi-character symbols, and $\Longleftrightarrow$ is not a regular-expression
operator but is used here just to indicate that two whole strings are related):

\begin{alltt}
walk[Verb][Past] \(\Longleftrightarrow\) walked

kick[Verb][Past] \(\Longleftrightarrow\) kicked

think[Verb][Past] \(\Longleftrightarrow\) thinked

go[Verb][Past] \(\Longleftrightarrow\) goed
\end{alltt}

\noindent
Incorrect forms like \emph{*thinked} and \emph{*goed} can be overridden by 
defining a
smaller \fsm{} encoding the correct mappings and simply priority-unioning it with
the \fsm{} \verb!$productive_english!.

\begin{Verbatim}
$corrections = (
    (dig):(dug)
|   (go):(went)
|   (say):(said)
|   (think):(thought)
) ('[Verb]' '[Past]'):"" ;

$english = $^priority_union_input($corrections, 
                                  $productive_english) ;
\end{Verbatim}


Once defined, functions can be called directly in regular
expressions and used in the definition of yet other functions.  For
example, the normal composition of Q and R 
is \verb!Q _o_ R! (also typeable in Unicode as \verb!Q!~$\circ$~\verb!R!, using the
Unicode \acro{ring operator} character, U+2218); and if the input-side language of Q is I, then
the input-side language of \verb!Q _o_ R! may be a proper subset of I.
That is, one or more of the original input strings of Q may not be accepted by the 
composition.  The Lenient Composition of transducers Q and R accepts exactly the 
same input language as Q.  The
following definition of \verb!$^lenient_composition_input()! is
appropriate for the examples in Karttunen's regular formalization of Optimality Theory
\citep{karttunen:1998}, where the \verb!$base!
transducer encodes a lexicon, and the \verb!$filter! transducer
encodes an optimality rule or filter being composed
``underneath''
the lexicon.

\begin{Verbatim}
$^lenient_composition_input($base, $filter) {
    return $^priority_union_input($base _o_ $filter, $base) ;
}
\end{Verbatim}

\noindent
When, conversely, the rule or filter is being
composed ``on top of'' the lexicon, and the desire is to
preserve the output language of the lexicon, then the following
function \verb!$^lenient_composition_output! is appropriate.

\begin{Verbatim}
$^lenient_composition_output($filter, $base) {
    return $^priority_union_output($filter _o_ $base, $base) ;
}
\end{Verbatim}



\subsection{Function Call Semantics}

\Kleene{} maintains its environment as a directed graph of frames,
where each frame
contains a symbol table and both a dynamic link and a static link to other frames (or to null at the root of the environment).  When a function is called, a new
frame is allocated for its execution; the dynamic link of the
new frame points back to the frame
from which the function was called, and the static link points back to the
frame where the function was defined.  

The formal parameters of the function are bound, in the new frame's local
symbol table, to the passed-in argument values,\footnote{When an \fsm{} is passed as an argument, no copy is performed, and the local
parameter becomes an alias for the original \fsm{}.  If it is
necessary to pass a copy, the explicit \verb!$^copy()! function can be used
in the argument list.}  and any variables introduced in
the body of the function are also stored in the local symbol
table.  References to free (non-local) variables are resolved
through the static link, thus implementing lexical scope.  When the
function terminates, it pushes the return value on the interpreter stack; then
the calling frame, pointed to by the dynamic
pointer, is once again made the current frame.

This fairly standard environment design supports functions that call other
functions, functions that call themselves recursively, functions
that themselves contain local definitions of functions, etc.  

\subsubsection{Higher-order Functions}

\Kleene{} also supports higher-order functions that return functions,
as in the following example:

\begin{Verbatim}
// a function that returns a function that returns an FSM 
$^^append_suffix($suff) {
    // return a function, denoted here as an
    //   anonymous function
    return $^($a) { return $a $suff ; } ;
}

$^append_ing = $^^append_suffix(ing) ;
$^append_espVend = $^^append_suffix(as|is|os|us|u|i) ;

$net1 = $^append_ing(walk|talk) ;
$net2 = $^append_espVend(pens|dir) ;
\end{Verbatim}

\noindent Recall that the sigil \verb!$^! marks a function that returns an \fsm{}.
Similarly, the sigil \verb!$^^!, as in \verb!$^^append_suffix!, marks a function that
returns a function that returns an \fsm{}.  Note that the \texttt{return} statement in
this function returns a function, notated here as an anonymous function.

\begin{Verbatim}
// return an anonymous function
return $^($a) { return $a $suff ; } ;
\end{Verbatim}

\noindent
You can also avoid the use of anonymous functions by using a private function declaration inside
the outer function declaration, and then returning the name of the private function:

\begin{Verbatim}
$^^append_suffix($suff) {
    // declare a private function
    $^foo($a) {
        return $a $suff ; } ;
    }

    // then return that function
    return $^foo ;
}
\end{Verbatim}

The function \verb!$^append_ing! just concatenates \emph{ing} to
its \fsm{} argument, so \verb!$net1! will be set to an \fsm{} that
encodes the language containing \emph{walking} and \emph{talking}.
The function \verb!$^append_espVend! is designed to model the
suffixation of Esperanto verb endings to verb roots, and
\verb!$net2! is set to an \fsm{} that encodes the language
containing \str{pensas}, \str{pensis}, \str{pensos},
\str{pensus}, \str{pensu}, \str{pensi}, \str{diras}, \str{diris}, etc.


\subsection{Function Parameters with Default Values}

In what follows, the term \emph{parameter} is used for the local
parameters in a function definition, and the term \emph{argument} is
used for the values passed in a function call.  The parameters are bound to the passed-in 
function values when a function
is called.

Kleene functions can be defined to have \emph{required} and/or \emph{optional}
parameters, where optional parameters have explicit default
values.\cprotect\footnote{The Kleene argument-passing and parameter-binding scheme
is modeled on that of Python, minus the Python parameters denoted with
initial single and double asterisks.  In Python, a parameter with a name like
\verb!*foo! is bound to a tuple containing any extra positional arguments in
the call; and
a parameter with a name like \verb!**bar! is bound to a dictionary (hash table) containing any
extra name=value pairs in the call.} In
the following example, \verb!$a! and \verb!$b! are required parameters, and \verb!$c! and
\verb!$d! are optional parameters.

\begin{Verbatim}
$^myfunc($a, $b, $c = abc, $d = xyz) {
	return $a $b $c $d ;
}
\end{Verbatim}

\noindent
In the parameter list, any required parameters must precede any optional parameters.
A call to \verb!$^myfunc()! must include at least two arguments to bind to
the first two parameters---the \emph{required} parameters.
If a call to \verb!$^myfunc()! does not supply arguments for the \emph{optional}
parameters, here \verb!$c! and \verb!$d!, they are bound to the default values indicated
in the function definition.

A function call may contain \emph{positional} and/or \emph{named}
arguments, where any positional arguments must precede any named arguments.  A
named argument is of the form \emph{paramName}~=~\emph{value}.
The following function call contains two positional arguments and one named
argument:

\begin{Verbatim}
$net = $^myfunc(a*b+c?, [a-z]{3,6}, $d = ing) ;
\end{Verbatim}

\noindent
It is important to understand that there is not always a straightforward mapping
between positional arguments and required parameters, nor between named
arguments and optional parameters.  As in Python, positional arguments
are treated first; if there are \emph{n} positional arguments in the
call, their
values are bound to the first \emph{n} parameters, in syntactic order,
whether those
parameters are required (having no default value) or optional (having a
default value).  Any named arguments in the call are then used
to bind the same-named parameters, whether those parameters are
required or optional.  The following runtime errors are detected:

\begin{itemize}
\item
Passing more arguments than there are parameters
\item
Attempting to set a parameter twice, first by a positional argument and
then by a named argument
\item
Failure to set a required parameter
\end{itemize}

The use of optional parameters and named arguments makes function calling more flexible and
often more readable.  Consider the following definition of a function
with three required parameters:

\begin{Verbatim}
$^func($prefix, $root, $suffix) {
	return $prefix $root $suffix ;
}
\end{Verbatim}

\noindent
This function can be called with three positional arguments,

\begin{Verbatim}
$net = $^func(re, work, ing) ;
\end{Verbatim}

\noindent
or with named arguments in any order:

\begin{Verbatim}
$net1 = $^func($root=think, $prefix="", $suffix=ing) ;
$net2 = $^func($prefix=un, $suffix=ing, $root=do) ;
\end{Verbatim}

\noindent
Function calls with positional arguments can, of course, easily become
opaque to human readers, especially when the function contains an unusually large number of parameters.

If parameters are optional---having default values in the function definition---then the call
may contain only the subset of arguments needed to override selected
defaults.  The function could, for example, expand the arguments, plus default
values, into larger \fsm{}s representing complex feature structures.

\begin{quote}
\textbf{Note to myself}: The \init{at\&t} Lextools contain a
built-in syntactic
feature that handles feature structures, linearizing
the component features in a predefined canonical order.  Show how this
can be done with Kleene functions with optional arguments.
\end{quote}



\section{Right-linear Phrase-structure Grammars}

\subsection{Right-linear Syntax}

While regular expressions are formally capable of describing any
regular language or regular relation, some linguistic
phenomena---especially productive morphological compounding and
derivation---can be awkward to model this way.  \Kleene{}
therefore provides right-linear phrase-structure grammars that
are similar in semantics, if not in syntax, to the
Xerox/\acro{parc} \texttt{lexc} language \citep{beesley+karttunen:2003}.  While general phrase-structure
grammars are context-free, requiring a push-down stack to parse, and so go beyond
regular power, a right-linear (or left-linear) grammar is regular and so can be
compiled into a finite-state machine.  

%The \Kleene{} phrase-structure syntax is beyond the scope of this paper.

A \Kleene{} phrase-structure \term{grammar} is a set of
\term{productions}, each
assigned to a variable with a \verb!$>! sigil.\footnote{If anyone has a better
suggestion for the syntax, please contact me.}  Productions may
include right-linear references to themselves or to other
productions, which might not yet be defined.  The key to understanding
productions is delayed evaluation.  The productions are parsed
immediately---and the parsed productions are stored as \init{ast}s in the
symbol table---but they are not evaluated until the entire grammar is built
into an \fsm{} via a call to the built-in function

\vspace{0.5cm}
\verb!$^start(!\emph{\$>StartProduction}\verb!)!
\vspace{0.5cm}

\noindent
which takes one production
name as its argument and treats it as the starting production of the whole
grammar.\footnote{Because it requires a special type of argument, \verb!$^start()!
is a wired-in function that cannot be aliased.  It is thus similar to what is called
a \emph{special form} in Lisp.}
The following example models a fragment of Esperanto noun morphotactics:

\begin{Verbatim}
$>Root = ( kat | hund | elefant | dom ) ( $>Root | $>AugDim ) ;
$>AugDim = ( eg | et )? $>Noun ;
$>Noun = o $>Plur ;
$>Plur = j? $>Case ;
$>Case = n? ;

$net = $^start($>Root) ;
\end{Verbatim}

\noindent
The syntax on the right-hand-side of productions is identical to regular-expression syntax, but allowing right-linear references to productions of the form
\verb!$>!\emph{Name}.  

\subsection{Right-linear Semantics}

\subsubsection{Enforcing the Right-linear Limitation}

After a production is parsed into an
\init{ast}, and before it is evaluated and stored in the symbol table, the
\init{ast} is sent a message to accept a visitor object
that ensures that
all references to productions are genuinely right-linear.  In the simplest cases,
a right-linear reference is visually on the far right-hand side of the
expression, as with \verb!$>Foo! in the following example:

\begin{Verbatim}
$>Production = a b c $>Foo ;
\end{Verbatim}

\noindent
The following production is illegal because the reference to \verb!$>Foo! is not right-linear.

\begin{Verbatim}
// illegal
$>Production = a b c $>Foo d ;
\end{Verbatim}


\noindent
In more complicated examples, multiple legal right-linear references can be unioned 
at the end of the expression:

\begin{Verbatim}
$>Production = a b c ( $>A | $>B | $>C ) ;
\end{Verbatim}

\noindent
Even more complicated examples are possible, as long as the references remain
right-linear. 

\begin{Verbatim}
$>Production = a b c ( d e f $>X | g h i j $>Y | k l m $>Z ) ;
\end{Verbatim}

\noindent
In simple terms, legal right-linear references have nothing concatenated
after them.
Violations of the right-linear restriction are found and reported
at production parse-time.

\subsubsection{The Implied Grammar}

The built-in \verb!$^start()! function takes the identifier of a single
production as its argument, and treats the start state of this production as the
start state of the resulting \fsm{}.  The overall implied grammar is the set
of productions including the
starting production, any productions referred to by the starting
production, and, 
recursively, any productions referred to by the referred-to productions.
The productions of the implied grammar
can also refer to normal \fsm{}-valued variables and
normal \fsm{}-valued function calls that must be defined at the time when
\verb!$^start()! is called.
The call to \verb!$^start()! fails if any referred-to production, variable
or function in the
implied grammar is
not yet defined.

If the call to \verb!$^start()! succeeds, it returns an \fsm{} value.  The
productions are not consumed during compilation, but remain available for
potential reuse.  While productions can be defined at any time and in any
place, it is often convenient to encapsulate an entire right-linear grammar
in a function, which can be called and then deleted when no longer
needed.

\begin{Verbatim}
$^esperanto_noun_function() {
	$>Root = (kat|hund|elefant|dom) ( $>Root | $>AugDim ) ;
	$>AugDim = ( eg | et )? $>Noun ;
	$>Noun = o $>Plur ;
	$>Plur = j? $>Case ;
	$>Case = n? ;

	return $^start($>Root) ;
}

$esp_nouns = $^esperanto_noun_function() ;
delete $^esperanto_noun_function ;
\end{Verbatim}

Deletion of the function severs the reference link between the function
identifier \verb!$^esperanto_noun_function! and the underlying object that
represents the function, allowing the memory tied up by that object to be
reclaimed.\footnote{The symbol tables and their objects are implemented in
Java, and objects are automatically garbage collected when there are no
more references to them.}  Another way to encapsulate right-linear
grammars, in stand-alone code blocks, is described in
section~\ref{sec:codeblock} on page~\pageref{sec:codeblock}.

\subsubsection{Uses of Right-linear Grammars}

\begin{quote}
\textbf{Note to myself}:   Make it clear that the productions can be defined in any order, as long as they
are all available when \verb!$^start()! is called. Similarly,
productions can refer to functions that have not yet been defined,
as long as those functions are available when \verb!$^start()! is
called.  The delayed evaluation allows grammars to be written in a top-down fashion.  Contrast
regular-expression assignments, which must be fully evaluatable at the
moment they are parsed, with right-linear grammars, where
evaluation is delayed.
Try to reconstruct the Aymara-derivation example and include it here.  
\end{quote}



\section{Scope}

\subsection{Assignments, Declarations and Local Scope}

Kleene, like Python, and unlike Java and \CPP{}, does not require
variables to be declared.
When a value is first assigned to a variable, as in

\begin{Verbatim}
$foo = a*b+[c-g] ;
\end{Verbatim}

\noindent
the statement automatically creates the variable \verb!$foo! and then binds
the \fsm{} value to the variable in the current local symbol table.  A
subsequent statement like

\begin{Verbatim}
$foo = (dog | cat | rat) s? ;
\end{Verbatim}

\noindent
causes the existing \verb!$foo! to be re-bound to the new \fsm{} 
value, again in the local symbol table.


\subsection{Stand-alone Code Blocks}

Kleene supports stand-alone code blocks, grouping a set of statements
that are to be evaluated in a new frame, which means in a new scope.
In the following example, a new frame/scope is allocated for the
stand-alone block, and the \verb!$foo! at point B is local to the block
and distinct from the
\verb!$foo! at point A. Inside the block, the local \verb!$foo! shadows
the \verb!$foo! defined at point A.  At the end of the code block, the new
frame/scope is released, and all memory used inside the block is freed
and made available for garbage collection.  At point C, the value of \verb!$foo! is the
language consisting of the word \emph{cat}, and the \verb!$foo! defined
at point B is out-of-scope and unavailable.

\begin{Verbatim}
$foo = cat ;        // point A

// start of code block
{
    $foo = dog ;    // point B
}
// end of code block

print $foo ;        // point C
\end{Verbatim}

\subsection{Function Blocks}

Function blocks are very similar to the stand-alone code blocks, being
evaluated in a new frame/scope.  The formal parameters of the function are
bound as local variables in the
new frame created to evaluate the function call, and any variables created in the block are also local.


\begin{Verbatim}
$^func($a, $b) {
    // parameters $a and $b are local
    $foo = $a $b ;    // $foo is local
    return $foo ;
}
\end{Verbatim}

\noindent
When the function terminates, it returns a value, unless it is a void function, and the
new frame is released, freeing any locally used memory for garbage
collection.  While locally used memory is released when a function returns, the
function definition itself is stored as an Abstract Syntax Tree (\init{ast}) that could
potentially tie up 
significant memory, and that memory is retained until the function definition
itself is deleted or goes out of scope.  In contrast, the \init{ast} representing a
stand-alone code block is released as soon as its execution is completed.

Note that the blocks of code in \texttt{if-elsif-else} statements and \texttt{while}
loops are not evaluated inside a new frame/scope.

\begin{Verbatim}
if (#^numStates($fst) < 30) {
    // this block is not executed in a new frame
    draw $fst ;
} else {
    // this block is not executed in a new frame
    print "the fst is too big to draw" ;
}
\end{Verbatim}


\subsection{External Variables}

Normally, from inside function blocks and stand-alone code blocks,
it is not possible to change the value of non-local variables,
i.e., variables that are defined in ``higher'' frames; nor is it
possible to delete such variables.  In exceptional cases/, it may be useful
or necessary for code within a stand-alone code block or function
block to change the value of a variable or variables outside that
scope.  To allow this, the variable or variables to be changed must
be overtly declared \texttt{external} at the top of the stand-alone
code block or function block.\footnote{The Python \texttt{global}
declaration has a very similar function.}  In the following
example, \verb!$foo! is declared external inside a stand-alone
block, and so the \verb!$foo! referred to at points B and C is the
same \verb!$foo! referred to at point A, and the value of
\verb!$foo! at point C is the language containing the single string
\emph{dog}.

\begin{samepage}
\begin{Verbatim}
$foo = cat ;        // point A
{
    external $foo ; 
    $foo = dog ;    // point B
}
print $foo ;        // point C
assert #^equivalent($foo, dog) ;
\end{Verbatim}
\end{samepage}

\noindent
Similarly in function blocks, external declarations allow a function to change the value
of variables outside the function's own block/scope.  The following function could be
called repeatedly to union a number of arguments into \verb!$result!.

\begin{samepage}
\begin{Verbatim}
$result = ~.* ; // point A, $result set to the empty language
                // the empty language could also be denoted 
                //     as a-a, etc.
^func($fst) {
    external $result ;
    $result = $result | $fst ;  // point B: 
                                // changes $result at point A
}
\end{Verbatim}
\end{samepage}

\noindent
Similarly, a non-local variable can be deleted, from inside a
function block or stand-alone code block, only if it has been
declared external.

\begin{samepage}
\begin{Verbatim}
$foo = foo ;
{
    delete $foo ;  // this is illegal
}
\end{Verbatim}
\end{samepage}

\begin{samepage}
\begin{Verbatim}
$foo = foo ;  // point A
{
    external $foo ;
    delete $foo ;  // deletes the variable at point A
}
\end{Verbatim}
\end{samepage}

Note that Kleene, consistent with its lexical scope, searches for
the external binding of a variable \verb!$var! declared external in
a function block by
searching up the \emph{static} environment links.  If multiple
\verb!$var! variables are in use in the program, you can see
which \verb!$var! is referred to by
looking at the source code and identifying the \verb!$var! that
is in scope where the function is defined.\footnote{In the
alternative, and rather old-fashioned, dynamic scope, the variable
referred to by the \texttt{external} statement would be the one
active at the point where the function is \emph{called}, and this
could of course change for each call.}

An \texttt{external} statement can appear only in a stand-alone code block or in a
function block, and it must precede any other kind of statement.  There can be multiple
\texttt{external} statements at the beginning of a block, 
and each statement can include multiple
identifiers, optionally separated by commas.

\begin{samepage}
\begin{Verbatim}
{
    external $foo ;
    external $foo, $bar, $result ;  // optional commas
    external $sum $avg $collection ;

    // other statements here
}
\end{Verbatim}
\end{samepage}


\subsection{Free Variables}

In general, expressions inside a stand-alone code block, or inside a
function block, can always \emph{refer} to variables outside the local
scope, to retrieve their values, but they cannot \emph{change} the value
of such variables, or \emph{delete} them,  unless they are expressly declared to be external. In
the following example, at point B, \verb!$foo! is referred to, and its
value retrieved, and this is legal and normal.  Because there is no
local binding of \verb!$foo!, Kleene searches up the static environment
links to find the first higher frame that contains a binding for
\verb!$foo!,  and returns the value.  In such a case, \verb!$foo! is
known as a free variable.

\begin{samepage}
\begin{Verbatim}
$foo = dog | cat | rat ;  // point A
{
    $bar = $foo s? ;      // point B, $foo is a free variable
    print $bar ;
}
\end{Verbatim}
\end{samepage}

\noindent 
Similarly, functions can refer to free variables.

\begin{samepage}
\begin{Verbatim}
$foo = dog | cat | rat ;  // point A

$^myfunc($a)
{
    $bar = $foo $a ;      // point B, $foo is a free variable
    return $bar ;
}
\end{Verbatim}
\end{samepage}


In an assignment statement within a block, free variables occur only on the right-hand side.
If a variable, such as \verb!$bar! at point B, 
appears on the left-hand side of an assignment, then its value is being
changed, and it is assumed to be local---and is created locally if it doesn't already
exist---unless it was overtly declared to be external.

\subsection{Combining Free and Local Usage}

It is possible to write a stand-alone code block or function block that first retrieves
the value of a
variable \verb!$var! as a free variable, and then subsequently tries to create and set
\verb!$var! as a local variable.

\begin{samepage}
\begin{Verbatim}
// a bad, confusing example
{
    $a = a b c $var ;  // point A: $var is a free variable
    // ...
    $var = a*b+[c-g] ; // point B: attempt to create/set
                       //     $var as a local variable
    // ...
}
\end{Verbatim}
\end{samepage}

\noindent
The statement at point B creates and sets \verb!$var! as a local variable because it was
not declared external.  The same problem can arise in a single assignment statement,
where a variable name appears both on the right-hand and left-hand sides of an
assignment.

\begin{samepage}
\begin{Verbatim}
// another bad, confusing example
$var = xyz ;
{
    $var = a b c $var ;  
    // ...
}
\end{Verbatim}
\end{samepage}

\noindent
In the assignment statement, the right-hand side is evaluated first, including the
retrieval of the value of \verb!$var! as a free variable.  Then, because \verb!$var! was
not declared external, it would attempt to create a local \verb!$var! and bind it to the
value of the right-hand side.


While such code makes sense theoretically, and could be allowed,
it is dangerously confusing and probably represents a programming error.  For this
reason, Kleene detects such cases and generates an exception at execution
time.\footnote{Python also disallows such usage, and it generates an error at
function-definition time.}


\subsection{Export Statements}

As a questionable experiment, Kleene supports \texttt{export} statements that can
appear only in a stand-alone code block, and which cause a local
variable, and its bound value, to be ``exported'' up from the current
frame to the mother frame.\footnote{For stand-alone code blocks, the
static mother frame and the dynamic mother frame are the same.} Consider
first the following example, which creates a local \verb!#var! inside a
stand-alone block and then tries to reference it after the block has
terminated.

\begin{samepage}
\begin{Verbatim}
{
    $var = abc ;	// point A
}
print $var ;  // point B: error, $var is out of scope
\end{Verbatim}
\end{samepage}

\noindent
This example generates an exception because \verb!$var! was created at point
A but is out of scope and unavailable at point B.  However, the example can be made to work by exporting \verb!$var!.

\begin{samepage}
\begin{Verbatim}
{
    $var = abc ;	// point A
    export $var ;	// export $var to the mother frame
}
print $var ;  // point B: no error, $var has the value "abc"
\end{Verbatim}
\end{samepage}

So far, exporting a value from a stand-alone code block looks a lot like
calling a function that returns a value.  A stand-alone code block can also
contain multiple \texttt{export} statements,
which can appear anywhere (but after \texttt{external} declarations, if
any).  A single \texttt{export} statement can list multiple variables,
optionally separated by commas.

\begin{samepage}
\begin{Verbatim}
{
    $foo = abc ;
    $bar = xyz ;
    export $foo, $bar ;

    $a = a ;
    $b = b ;
    $c = c ;
    export $a $b $c ;
}
\end{Verbatim}
\end{samepage}


\subsection{Practical Use of Code Blocks}

\label{sec:codeblock}

Finite-state machines can often get alarmingly big, sometimes too big to
process; and \fsm{}s are normally persistent, taking up memory until
they are overtly deleted or go out of scope.  Stand-alone code blocks and function blocks
can be used to help minimize the use of memory when programming.

For example, in practical finite-state programming it is very common to
define a set of intermediate \fsm{}s and then combine them somehow into
the final desired \fsm{}.  The intermediate \fsm{}s can then be deleted
to allow their memory to be garbage collected.  Take the following
example that models simple Esperanto nouns.

\begin{Verbatim}
$nroot = elefant | kat | hund | bird ;  
//       elephant  cat    dog   bird
// $nroot could be expanded to thousands of roots
$augdim = eg | et ;
$num = j ;
$case = n ;

$nouns = $nroot $augdim* $num? $case? ;

// now delete the intermediate FSMs no longer needed
delete $nroot $augdim $num $case ;
\end{Verbatim}

\noindent
Of course, it requires some attention and discipline
to recognize and delete no-longer-needed intermediate \fsm{}s,
and it is far too easy to leave them lying around, taking up valuable memory.  

Kleene programmers writing such grammars are encouraged to group them into stand-alone 
code blocks that
either export the final value or declare an external variable and set it to the final
value, e.g.

\begin{samepage}
\begin{Verbatim}
{
    // intermediate FSMs 
    $nroot = elefant | kat | hund | bird ;
    $augdim = eg | et ;
    $nsuff = o ;
    $num = j ;
    $case = n ;
    // the final FSM 
    $nouns = $nroot $augdim* $nsuff $num? $case? ;

    export $nouns ;
}
\end{Verbatim}
\end{samepage}

\noindent
or

\begin{Verbatim}
$nouns = "" ;
{
    external $nouns ;

    // intermediate FSMs 
    $nroot = elefant | kat | hund | bird ;
    $augdim = eg | et ;
    $nsuff = o ;
    $num = j ;
    $case = n ;

    // set the final (external) value
    $nouns = $nroot $augdim* $nsuff $num? $case? ;
}
\end{Verbatim}

\noindent
Either way, at the end of the code block, its frame will be released and
all of its local memory will be freed for garbage collection.  Only the
variables and values explicitly exported, or declared external, will
remain.

Stand-alone code blocks can also be nested, e.g.\@ to model Esperanto
nouns and verbs, one might write the following:

\begin{Verbatim}
{
    {
        $nroot = elefant | kat | hund | bird ;
        $augdim = eg | et ;
        $nsuff = o ;
        $num = j ;
        $case = n ;
        $nouns = $nroot $augdim* $nsuff $num? $case? ;
        export $nouns ;
    }
    {
        $vroot = pens | ir | don | dir ;
        //     think    go   give  say
        $aspect = ad ;
        $vend = as | is | os | us | u | i ;
        $verbs = $vroot $aspect? $vend ;
        export $verbs ;
    }
    $esp = $nouns | $verbs ;
    export $esp ;
}
\end{Verbatim}

\noindent
After the evaluation of this nested block, only the final \verb!$esp!
variable would be available, and all the intermediate code and \fsm{s} 
would be released, as if they had been explicitly deleted.
Again, \texttt{export} is implemented as an experiment, and it remains
to be seen if it will prove truly useful.

\section{Language Restriction Expressions}

Kleene language-restriction expressions are regular-expression
abbreviations that denote regular \emph{languages} (not regular
\emph{relations}) and compile into \fsm{}s that are finite-state
acceptors.  For
example, the expression

\begin{Verbatim}
b => a _ c
\end{Verbatim}

\noindent
denotes the Universal Language minus all strings that violate
the restriction that any symbol \texttt{b} must
be preceded immediately by \texttt{a} and followed immediately by
\texttt{c}.  Thus the denoted language includes \emph{dog} and
\emph{elephant}, and all other strings that do not contain
\texttt{b}; and it contains strings like \emph{abc}, \emph{aaabcm},
\emph{qaaabcmmabcr} wherein every occurrence of \texttt{b} is
preceded by \texttt{a} and followed by \texttt{c}.  The language
excludes all strings, including \emph{bac}, \emph{abm} and
\emph{abcqqabr}, that contain any \texttt{b} that is not surrounded
with the specified left and right contexts.

In general, the language-restriction syntax is

\begin{alltt}
\emph{content} => \emph{leftContext} _ \emph{rightContext}
\end{alltt}

\noindent
where \emph{content}, \emph{leftContext} and \emph{rightContext}
can be arbitrarily complex regular expressions with the semantic
restriction that each must denote a regular language (not a
relation).  The \emph{leftContext} and/or \emph{rightContext} can
be omitted

\begin{Verbatim}
b => a _
b => _ c
\end{Verbatim}

\noindent
and word boundaries can be indicated with \texttt{\#}.  The
expression

\begin{Verbatim}
b => # _
\end{Verbatim}

\noindent
allows \texttt{b} to appear only at the beginning of a word, and,
similarly,

\begin{Verbatim}
b => _ #
\end{Verbatim}

\noindent
allows \texttt{b} only at the end of a word.  The following
expressions allows \texttt{abc} to appear only when followed by
\texttt{quam} and the end of the string.

\begin{Verbatim}
abc => _ quam #
\end{Verbatim}

\noindent
To include a literal pound sign (also known as the hash mark or
hash sign) in any regular expression, it should be literalized in
the usual Kleene ways:  either as \verb!\#! or \verb!"#"! or \verb![#]!. 

Restriction expressions can also include multiple contexts, separated by
\texttt{||}, a double vertical bar.  The following expression denotes the
Universal Language, minus any strings that violate the restriction that
each occurrence of \texttt{abc} must appear either at the beginning of a
string, at the end of a string, or in the context between \texttt{left}
and \texttt{right}.

\begin{Verbatim}
abc => #_ || _ # || left _ right 
\end{Verbatim}

\noindent
Where multiple contexts are provided, each example of the content
must appear in at least one of the contexts indicated.

Because restriction expressions are regular expressions that denote
regular languages and compile into acceptors, they can be assigned to
variables just like any other regular expressions.

\begin{Verbatim}
$var =  abc => left _ right ;
\end{Verbatim}


